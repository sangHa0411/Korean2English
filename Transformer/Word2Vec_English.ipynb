{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bca6dfa5-2dea-4863-864e-2b4d97318441",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader , Subset, random_split\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "524d827a-fa89-4f6f-856c-aa67796e7a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from itertools import chain\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e7e6bb4-1f01-4fbd-8ed1-c2a66db49270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from preprocessor.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from preprocessor import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad19416c-b328-4a6e-87b5-092a5919f1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd39baa1-a764-476e-ac2a-76cc51615449",
   "metadata": {},
   "source": [
    "## Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a439d6e1-22d4-408b-b87e-882ea145197e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = '../../Data/'\n",
    "data = pd.read_excel(dir_path + '한국어_대화체_번역.xlsx' , engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80ec5135-8d75-44e9-b75f-10eb1fe62845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>원문</th>\n",
       "      <th>번역문</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>이번 신제품 출시에 대한 시장의 반응은 어떤가요?</td>\n",
       "      <td>How is the market's reaction to the newly rele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>판매량이 지난번 제품보다 빠르게 늘고 있습니다.</td>\n",
       "      <td>The sales increase is faster than the previous...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>그렇다면 공장에 연락해서 주문량을 더 늘려야겠네요.</td>\n",
       "      <td>Then, we'll have to call the manufacturer and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>네, 제가 연락해서 주문량을 2배로 늘리겠습니다.</td>\n",
       "      <td>Sure, I'll make a call and double the volume o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>지난 회의 마지막에 논의했던 안건을 다시 볼까요?</td>\n",
       "      <td>Shall we take a look at the issues we discusse...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             원문  \\\n",
       "0   이번 신제품 출시에 대한 시장의 반응은 어떤가요?   \n",
       "1    판매량이 지난번 제품보다 빠르게 늘고 있습니다.   \n",
       "2  그렇다면 공장에 연락해서 주문량을 더 늘려야겠네요.   \n",
       "3   네, 제가 연락해서 주문량을 2배로 늘리겠습니다.   \n",
       "4   지난 회의 마지막에 논의했던 안건을 다시 볼까요?   \n",
       "\n",
       "                                                 번역문  \n",
       "0  How is the market's reaction to the newly rele...  \n",
       "1  The sales increase is faster than the previous...  \n",
       "2  Then, we'll have to call the manufacturer and ...  \n",
       "3  Sure, I'll make a call and double the volume o...  \n",
       "4  Shall we take a look at the issues we discusse...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_size = len(data)\n",
    "data[['원문','번역문']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b40de1da-aefe-40d8-8256-95831d126126",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_data = data['번역문']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63a87ac8-68d1-480c-b129-cc5a94bc4689",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_encoder = Preprocessor(en_data, word_tokenize, th=3)\n",
    "\n",
    "en_encoder.build_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04bd8089-944a-4c8d-b35f-7f1e3b57b214",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_idx2word = en_encoder.get_idx2word()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e723113-2c1f-4fa5-b43d-fcdb3700f9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_df = pd.DataFrame({'INDEX' : list(en_idx2word.keys()), \n",
    "                      'TOKEN' : list(en_idx2word.values())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "691284ad-6677-4421-af97-e869de10d952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INDEX</th>\n",
       "      <th>TOKEN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;PAD&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>&lt;UNK&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;SOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>&lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>customer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   INDEX     TOKEN\n",
       "0      0     <PAD>\n",
       "1      1     <UNK>\n",
       "2      2     <SOS>\n",
       "3      3     <EOS>\n",
       "4      4  customer"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3caccd60-b9b8-44b7-8ffc-05f211811b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_df.to_csv('./Embedding/csv/en_idx2word.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34de44d5-5b83-4244-b7d9-8d90fafeb658",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a436ecf5-8746-4ae6-81c6-425e53cb42be",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_idx_data = en_encoder.encode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f708479b-eae6-4276-a0f6-faa9e4e18dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(idx_data, window_size=9)  :\n",
    "    \n",
    "    context_data = []\n",
    "    \n",
    "    for i in range(len(idx_data)) :\n",
    "        idx_list = idx_data[i]\n",
    "        if len(idx_list) < window_size :\n",
    "            continue\n",
    "        for j in range(len(idx_list) - window_size) :\n",
    "            context_data.append(idx_list[j:j+window_size])\n",
    "    \n",
    "    context_data = np.array(context_data)\n",
    "    random.shuffle(context_data)\n",
    "    \n",
    "    mid_point = int(window_size/2)\n",
    "    cen_data = context_data[:,mid_point]\n",
    "    neighbor_data = np.hstack([context_data[:,:mid_point], context_data[:,mid_point+1:]])\n",
    "            \n",
    "    return cen_data, neighbor_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb527da8-a9e8-4cdf-bfa1-216dac9951a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 13\n",
    "cen_data, neigh_data = make_data(en_idx_data, 13)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1ed2ea-1ff4-409c-84d0-4665b31b4fb9",
   "metadata": {},
   "source": [
    "## Dataset & Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff89cba3-62d1-4ad8-b361-c3d78a880f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingDataset(Dataset) :\n",
    "\n",
    "    def __init__(self, cen_data, neighbor_data, val_ratio=0.1) :\n",
    "        super(EmbeddingDataset , self).__init__()\n",
    "        self.c_data = cen_data\n",
    "        self.n_data = neighbor_data\n",
    "        self.val_ratio = val_ratio\n",
    "\n",
    "    def __len__(self) :\n",
    "        return len(self.c_data)\n",
    "\n",
    "    def __getitem__(self , idx) :\n",
    "        return self.c_data[idx], self.n_data[idx]\n",
    "    \n",
    "    def split(self) :\n",
    "        n_val = int(len(self) * self.val_ratio)\n",
    "        n_train = len(self) - n_val\n",
    "        train_set, val_set = random_split(self, [n_train, n_val])\n",
    "        \n",
    "        return train_set, val_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b136098-bf8c-4874-993d-3ed1f8ec7d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "\n",
    "dataset = EmbeddingDataset(cen_data, neigh_data)\n",
    "train_data, val_data = dataset.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4988014-6b3e-4a7e-b982-b58e827597b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data,\n",
    "                          num_workers=4,\n",
    "                          shuffle=True,\n",
    "                          batch_size=batch_size)\n",
    "\n",
    "val_loader = DataLoader(val_data,\n",
    "                        num_workers=4,\n",
    "                        shuffle=False,\n",
    "                        batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3e93ca-a932-4239-b23b-7f267d04cb52",
   "metadata": {},
   "source": [
    "## Device & Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8473cac4-2696-4ac3-ae99-3f27c1172e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "random.seed(20210906)\n",
    "torch.cuda.manual_seed_all(20210906)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44638e8a-82ce-43e7-8d8d-534d9754ee57",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e79c374-8057-417a-bdb8-e4343cc5dc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipGram(nn.Module) :\n",
    "    \n",
    "    def __init__(self, em_size, v_size, window_size) :\n",
    "        super(SkipGram, self).__init__()\n",
    "        self.em_size = em_size\n",
    "        self.v_size = v_size\n",
    "        self.window_size = window_size\n",
    "    \n",
    "        self.embedding = nn.Embedding(num_embeddings=v_size,\n",
    "                                      embedding_dim=em_size,\n",
    "                                      padding_idx=0)\n",
    "        self.o_layer = nn.Linear(em_size, v_size*(window_size-1))\n",
    "        \n",
    "        self.init_param()\n",
    "        \n",
    "    def init_param(self) :\n",
    "        nn.init.normal_(self.embedding.weight, mean=0.0, std=0.1)\n",
    "        \n",
    "        nn.init.xavier_normal_(self.o_layer.weight)\n",
    "        nn.init.zeros_(self.o_layer.bias)\n",
    "        \n",
    "    def forward(self, in_tensor) :\n",
    "        in_tensor = in_tensor.unsqueeze(1)\n",
    "        em_tensor = self.embedding(in_tensor)\n",
    "        \n",
    "        o_tensor = self.o_layer(em_tensor)\n",
    "        o_tensor = torch.reshape(o_tensor, (-1,self.window_size-1,self.v_size))\n",
    "        \n",
    "        return o_tensor\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0b2e34d2-202a-4f8a-ad5f-c6adfe0f1ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOW(nn.Module) :\n",
    "    \n",
    "    def __init__(self, em_size, v_size) :\n",
    "        super(CBOW, self).__init__()\n",
    "        self.em_size = em_size\n",
    "        self.v_size = v_size\n",
    "    \n",
    "        self.embedding = nn.Embedding(num_embeddings=v_size,\n",
    "                                      embedding_dim=em_size,\n",
    "                                      padding_idx=0)\n",
    "        self.o_layer = nn.Linear(em_size, v_size)\n",
    "        \n",
    "        self.init_param()\n",
    "        \n",
    "    def init_param(self) :\n",
    "        nn.init.normal_(self.embedding.weight, mean=0.0, std=0.1)\n",
    "        \n",
    "        nn.init.xavier_normal_(self.o_layer.weight)\n",
    "        nn.init.zeros_(self.o_layer.bias)\n",
    "        \n",
    "    def forward(self, in_tensor) :\n",
    "        em_tensor = self.embedding(in_tensor)\n",
    "        h_tensor = torch.mean(em_tensor, dim=1)\n",
    "        \n",
    "        o_tensor = self.o_layer(h_tensor)\n",
    "        \n",
    "        return o_tensor\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "03bb9126-c21f-4d39-aef4-971c09988930",
   "metadata": {},
   "outputs": [],
   "source": [
    "em_dim = 512\n",
    "v_size = len(en_df)\n",
    "\n",
    "w2v_model = SkipGram(em_dim, v_size, window_size).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152b2c80-c2a5-47e9-a512-6e224ca95958",
   "metadata": {},
   "source": [
    "## Optimizer & Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d202481b-5644-441e-b6bf-2c000da91342",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_size = 20\n",
    "init_lr = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1aa47023-375f-4927-b3f2-172fa507a0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_fn(epoch,lr) :\n",
    "    \n",
    "    decay_lr = lr*(epoch/epoch_size)\n",
    "    \n",
    "    return (lr-decay_lr)/lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "35476cc5-dd4b-4185-b1c5-534cf5b48dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(w2v_model.parameters(), lr=init_lr)\n",
    "scheduler = optim.lr_scheduler.LambdaLR(optimizer, \n",
    "                                        lr_lambda = lambda epoch: linear_fn(epoch, init_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082d1cc9-f93c-4b79-b711-16f3b6f5706a",
   "metadata": {},
   "source": [
    "## Acc & Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "36b940d8-dc62-4902-956e-4a8d01210be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_fn(y_output , y_label) :\n",
    "    y_arg = torch.argmax(y_output, dim=-1)\n",
    "    y_acc = (y_arg == y_label).float()\n",
    "    y_acc = torch.mean(y_acc)\n",
    "    return y_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "086326d5-88d4-4dc3-ace6-b18af4b5dfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba3b363-a75e-4c9d-b5d6-66ed16167768",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c36e41b7-a828-4679-b762-822f4a849b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_loss = np.inf\n",
    "stop_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "72567175-08e7-4131-b409-1804ded29570",
   "metadata": {},
   "outputs": [],
   "source": [
    "def progressLearning(epoch, value, endvalue, bar_length=50):\n",
    "    percent = float(value + 1) / endvalue\n",
    "    arrow = '-' * int(round(percent * bar_length)-1) + '>'\n",
    "    spaces = ' ' * (bar_length - len(arrow))\n",
    "\n",
    "    sys.stdout.write(\"\\rEpoch [{0}] : [{1}] {2}/{3}\".format(epoch, \n",
    "                                                            arrow + spaces, \n",
    "                                                            value+1 , \n",
    "                                                            endvalue))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6be92e22-c655-4938-8c27-8b902d2f41f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader) :\n",
    "    with torch.no_grad() :\n",
    "        model.eval()\n",
    "        loss_eval = 0.0\n",
    "        acc_eval = 0.0\n",
    "    \n",
    "        for cen_data, neigh_data in test_loader :\n",
    "            cen_data = cen_data.long().to(device)\n",
    "            neigh_data = neigh_data.long().to(device)\n",
    "\n",
    "            neigh_out = model(cen_data)\n",
    "            \n",
    "            neigh_out = torch.reshape(neigh_out, (-1,v_size))\n",
    "            neigh_data = torch.reshape(neigh_data, (-1,))\n",
    "            \n",
    "            loss_eval += loss_fn(neigh_out , neigh_data)\n",
    "            acc_eval += acc_fn(neigh_out , neigh_data)\n",
    "\n",
    "        model.train()\n",
    "        loss_eval /= len(test_loader)\n",
    "        acc_eval /= len(test_loader)\n",
    "        \n",
    "    return loss_eval , acc_eval  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1171deff-ef35-4023-8ddd-d55438d2d080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0] : [------------------------------------------------->] 379/379\tVal Loss : 6.357 \t Val Accuracy : 0.075\n",
      "Epoch [1] : [------------------------------------------------->] 379/379\tVal Loss : 6.127 \t Val Accuracy : 0.086\n",
      "Epoch [2] : [------------------------------------------------->] 379/379\tVal Loss : 5.873 \t Val Accuracy : 0.079\n",
      "Epoch [3] : [------------------------------------------------->] 379/379\tVal Loss : 5.648 \t Val Accuracy : 0.070\n",
      "Epoch [4] : [------------------------------------------------->] 379/379\tVal Loss : 5.433 \t Val Accuracy : 0.098\n",
      "Epoch [5] : [------------------------------------------------->] 379/379\tVal Loss : 5.330 \t Val Accuracy : 0.108\n",
      "Epoch [6] : [------------------------------------------------->] 379/379\tVal Loss : 5.225 \t Val Accuracy : 0.110\n",
      "Epoch [7] : [------------------------------------------------->] 379/379\tVal Loss : 5.150 \t Val Accuracy : 0.112\n",
      "Epoch [8] : [------------------------------------------------->] 379/379\tVal Loss : 5.105 \t Val Accuracy : 0.116\n",
      "Epoch [9] : [------------------------------------------------->] 379/379\tVal Loss : 5.064 \t Val Accuracy : 0.121\n",
      "Epoch [10] : [------------------------------------------------->] 379/379\tVal Loss : 5.038 \t Val Accuracy : 0.123\n",
      "Epoch [11] : [------------------------------------------------->] 379/379\tVal Loss : 5.023 \t Val Accuracy : 0.125\n",
      "Epoch [12] : [------------------------------------------------->] 379/379\tVal Loss : 5.005 \t Val Accuracy : 0.126\n",
      "Epoch [13] : [------------------------------------------------->] 379/379\tVal Loss : 4.988 \t Val Accuracy : 0.127\n",
      "Epoch [14] : [------------------------------------------------->] 379/379\tVal Loss : 4.978 \t Val Accuracy : 0.128\n",
      "Epoch [15] : [------------------------------------------------->] 379/379\tVal Loss : 4.968 \t Val Accuracy : 0.129\n",
      "Epoch [16] : [------------------------------------------------->] 379/379\tVal Loss : 4.956 \t Val Accuracy : 0.131\n",
      "Epoch [17] : [------------------------------------------------->] 379/379\tVal Loss : 4.951 \t Val Accuracy : 0.132\n",
      "Epoch [18] : [------------------------------------------------->] 379/379\tVal Loss : 4.944 \t Val Accuracy : 0.132\n",
      "Epoch [19] : [------------------------------------------------->] 379/379\tVal Loss : 4.939 \t Val Accuracy : 0.133\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epoch_size) :\n",
    "    idx = 0\n",
    "\n",
    "    for cen_data, neigh_data in train_loader :\n",
    "        cen_data = cen_data.long().to(device)\n",
    "        neigh_data = neigh_data.long().to(device)\n",
    "\n",
    "        neigh_out = w2v_model(cen_data)\n",
    "        \n",
    "        neigh_out = torch.reshape(neigh_out, (-1,v_size))\n",
    "        neigh_data = torch.reshape(neigh_data, (-1,))\n",
    "            \n",
    "        loss = loss_fn(neigh_out , neigh_data)\n",
    "        acc = acc_fn(neigh_out , neigh_data)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        progressLearning(epoch, idx, len(train_loader))\n",
    "        idx += 1\n",
    "\n",
    "    val_loss, val_acc = evaluate(w2v_model, val_loader)\n",
    "    \n",
    "    if val_loss < min_loss :\n",
    "        min_loss = val_loss\n",
    "        torch.save({'epoch' : (epoch) ,  \n",
    "                    'model_state_dict' : w2v_model.state_dict() , \n",
    "                    'loss' : val_loss.item() , \n",
    "                    'acc' : val_acc.item()} , \n",
    "                    f'./Embedding/model/checkpoint_w2v_english.pt')        \n",
    "        stop_count = 0 \n",
    "    else :\n",
    "        stop_count += 1\n",
    "        if stop_count >= 5 : \n",
    "            print('\\tTraining Early Stopped')\n",
    "            break\n",
    "            \n",
    "    scheduler.step()\n",
    "    print('\\tVal Loss : %.3f \\t Val Accuracy : %.3f' %(val_loss, val_acc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5ef6e9ed-364e-43a2-9aa9-44df6245f120",
   "metadata": {},
   "outputs": [],
   "source": [
    "em_weight = w2v_model.embedding.weight\n",
    "o_weight = w2v_model.o_layer.weight.view(-1,window_size-1,em_dim)\n",
    "o_weight = torch.mean(o_weight, dim=1)\n",
    "en_weight = (em_weight + o_weight)/2\n",
    "\n",
    "o_bias = w2v_model.o_layer.bias.view(-1,window_size-1)\n",
    "o_bias = torch.mean(o_bias, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d1b1b6c9-84b3-4204-b5ce-3931770a7bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_bias = o_bias.detach().cpu().numpy()\n",
    "en_weight = en_weight.detach().cpu().numpy() \n",
    "en_weight[0] = 0.0\n",
    "\n",
    "np.save('./Embedding/array/en_weight.npy', en_weight)\n",
    "np.save('./Embedding/array/en_bias.npy', en_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd57454-962c-4f0c-8ab3-f6e3be45d038",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
