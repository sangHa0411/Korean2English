{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c3d8a4a-9511-4729-86a8-685dd81594d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader , Subset, random_split\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfc08618-d053-4353-a3b1-cfa33c352726",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from itertools import chain\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "921564bf-6b90-47d1-a53e-1e95d8a727df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from preprocessor.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from preprocessor import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17e179df-ca3d-4cc8-a7c7-ea50fff96dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d9505f6-7161-462f-af87-f3d49bf6931e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56664b34-2f11-4b8a-a110-ab4035443932",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from konlpy.tag import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9b02ee3-d796-436f-b597-b099f11c7e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mecab = Mecab()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67a2d84-b00e-43b5-9e15-e80c215412ee",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7302e5d3-12d0-49e8-8613-0c5b2230fb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = '../../Data/'\n",
    "data = pd.read_excel(dir_path + '한국어_대화체_번역.xlsx' , engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4da2f22-ec0d-428f-af99-7b5989e7befc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>원문</th>\n",
       "      <th>번역문</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>이번 신제품 출시에 대한 시장의 반응은 어떤가요?</td>\n",
       "      <td>How is the market's reaction to the newly rele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>판매량이 지난번 제품보다 빠르게 늘고 있습니다.</td>\n",
       "      <td>The sales increase is faster than the previous...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>그렇다면 공장에 연락해서 주문량을 더 늘려야겠네요.</td>\n",
       "      <td>Then, we'll have to call the manufacturer and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>네, 제가 연락해서 주문량을 2배로 늘리겠습니다.</td>\n",
       "      <td>Sure, I'll make a call and double the volume o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>지난 회의 마지막에 논의했던 안건을 다시 볼까요?</td>\n",
       "      <td>Shall we take a look at the issues we discusse...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             원문  \\\n",
       "0   이번 신제품 출시에 대한 시장의 반응은 어떤가요?   \n",
       "1    판매량이 지난번 제품보다 빠르게 늘고 있습니다.   \n",
       "2  그렇다면 공장에 연락해서 주문량을 더 늘려야겠네요.   \n",
       "3   네, 제가 연락해서 주문량을 2배로 늘리겠습니다.   \n",
       "4   지난 회의 마지막에 논의했던 안건을 다시 볼까요?   \n",
       "\n",
       "                                                 번역문  \n",
       "0  How is the market's reaction to the newly rele...  \n",
       "1  The sales increase is faster than the previous...  \n",
       "2  Then, we'll have to call the manufacturer and ...  \n",
       "3  Sure, I'll make a call and double the volume o...  \n",
       "4  Shall we take a look at the issues we discusse...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['원문','번역문']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21eb953-8b85-4734-a914-0f25b093e4ad",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07550a9f-3fcc-4248-a690-b1274e82bb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_data = data['번역문']\n",
    "kor_data = data['원문']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7cc61f2f-eb6f-4262-8291-1c85987339c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_encoder = Preprocessor(en_data, word_tokenize, th=3)\n",
    "kor_encoder = Preprocessor(kor_data, mecab.morphs, th=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd5ad4b7-d2dd-4d5c-b942-dbee312eda94",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_idx_data = en_encoder.encode()\n",
    "kor_idx_data = kor_encoder.encode()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9e94be-38c0-401e-8afd-c66b5241ea7b",
   "metadata": {},
   "source": [
    "## Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c7448b2-6fbf-41e6-801d-06255d3b6b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslationDataset(Dataset) :\n",
    "\n",
    "    def __init__(self, en_index, de_index, val_ratio=0.1) :\n",
    "        super(TranslationDataset , self).__init__()\n",
    "        self.idx_data = self.build_data(en_index, de_index)\n",
    "        self.val_ratio = val_ratio\n",
    "        \n",
    "    def build_data(self, en_data, de_data) :\n",
    "        data_len = len(en_data)\n",
    "        idx_data = [(en_data[i],de_data[i]) for i in range(data_len)]\n",
    "        \n",
    "        return idx_data\n",
    "\n",
    "    def __len__(self) :\n",
    "        return len(self.idx_data)\n",
    "\n",
    "    def __getitem__(self , idx) :\n",
    "        return self.idx_data[idx]\n",
    "    \n",
    "    def split(self) :\n",
    "        n_val = int(len(self) * self.val_ratio)\n",
    "        n_train = len(self) - n_val\n",
    "        train_set, val_set = random_split(self, [n_train, n_val])\n",
    "        \n",
    "        return train_set, val_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84ba6a06-8c88-444a-bc01-aedc975b4335",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_sampler(len_data, batch_size, size_gap=5) :\n",
    "    \n",
    "    data_size = len(len_data)\n",
    "\n",
    "    batch_map = defaultdict(list)\n",
    "    idx_list = []\n",
    "    batch_index = []\n",
    "    \n",
    "    for idx in range(data_size) :\n",
    "        src_len, tar_len = len_data[idx]\n",
    "        src = (src_len // size_gap)\n",
    "        tar = (tar_len // size_gap)\n",
    "        batch_map[(src,tar)].append(idx)\n",
    "        \n",
    "    batch_key = list(batch_map.keys())\n",
    "    batch_key = sorted(batch_key, key=lambda x : (-x[0], -x[1]))\n",
    "    for key in batch_key :\n",
    "        idx_list.extend(batch_map[key])\n",
    "    \n",
    "    for i in range(0, data_size, batch_size) :\n",
    "        batch_index.append(idx_list[i:i+batch_size])\n",
    "    \n",
    "    random.shuffle(batch_index)\n",
    "    \n",
    "    return batch_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cacda16e-8b22-4108-a4a4-2cee54b258c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch_samples) :\n",
    "    \n",
    "    batched_samples = sorted(batch_samples, key=lambda x:x[0], reverse=True)\n",
    "    \n",
    "    src_tensor = []\n",
    "    tar_tensor = []\n",
    "    for src_idx, tar_idx in batched_samples:\n",
    "        src_tensor.append(torch.tensor(src_idx))\n",
    "        tar_tensor.append(torch.tensor(tar_idx))\n",
    "        \n",
    "    src_tensor = pad_sequence(src_tensor, batch_first=True, padding_value=Token.PAD_IDX.value)\n",
    "    src_len = src_tensor.shape[1]\n",
    "    src_pad = F.pad(src_tensor, (0,max_len-src_len), 'constant', Token.PAD_IDX.value)\n",
    "    \n",
    "    tar_tensor = pad_sequence(tar_tensor, batch_first=True, padding_value=Token.PAD_IDX.value)\n",
    "    tar_len = tar_tensor.shape[1]\n",
    "    tar_pad = F.pad(tar_tensor, (0,max_len+1-tar_len), 'constant', Token.PAD_IDX.value)\n",
    "    \n",
    "    return {'encoder_in' : src_pad, 'decoder_in' : tar_pad[:,:-1], 'decoder_out' : tar_pad[:,1:]}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54c4b7a9-9f68-450b-9927-5df5760a64b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 25\n",
    "batch_size = 80\n",
    "\n",
    "dataset = TranslationDataset(kor_idx_data, en_idx_data)\n",
    "train_data, val_data = dataset.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b05ed46d-fa1e-41e3-8fde-f7b0b3a325a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_src_len = [len(data[0]) for data in train_data]\n",
    "train_tar_len = [len(data[1]) for data in train_data]\n",
    "\n",
    "train_len = [(train_src_len[i],train_tar_len[i]) for i in range(len(train_data))]\n",
    "\n",
    "val_src_len = [len(data[0]) for data in val_data]\n",
    "val_tar_len = [len(data[1]) for data in val_data]\n",
    "\n",
    "val_len = [(val_src_len[i],val_tar_len[i]) for i in range(len(val_data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8fde3343-4836-4570-b13f-d409b855f6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data,\n",
    "                          num_workers=4,\n",
    "                          collate_fn=collate_fn,\n",
    "                          batch_sampler=batch_sampler(train_len, batch_size))\n",
    "\n",
    "val_loader = DataLoader(val_data,\n",
    "                        num_workers=4,\n",
    "                        collate_fn=collate_fn,\n",
    "                        batch_sampler=batch_sampler(val_len, batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c4e0c2-4c37-4022-a513-432666621d0d",
   "metadata": {},
   "source": [
    "## Device & Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "122ff02d-45fe-42f2-8880-c4d08b0629c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "random.seed(20210906)\n",
    "torch.cuda.manual_seed_all(20210906)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed26eb4-4524-4c40-9421-62d25278837d",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8385ddf1-9fc9-483a-ab20-fca7d280ca20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PaddingMask(nn.Module) :\n",
    "\n",
    "    def __init__(self, sen_size) :\n",
    "        super(PaddingMask , self).__init__() \n",
    "        self.sen_size = sen_size\n",
    "    \n",
    "    def forward(self, in_tensor) :\n",
    "        batch_size = in_tensor.shape[0]\n",
    "        # mask tensor which element is 0.0\n",
    "        flag_tensor = torch.where(in_tensor == 0.0 , 1.0 , 0.0)\n",
    "        # shape : (batch_size, 1, 1, sen_size)\n",
    "        flag_tensor = torch.reshape(flag_tensor , (batch_size, 1, 1, self.sen_size)) \n",
    "        \n",
    "        return flag_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "00ca3d19-98ab-46c6-aaa3-2404596ac905",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LookAheadMask(nn.Module) :\n",
    "\n",
    "    def __init__(self, sen_size, cuda_flag) :\n",
    "        super(LookAheadMask, self).__init__() \n",
    "        self.sen_size = sen_size\n",
    "        self.mask_tensor = self.get_mask(sen_size).cuda() if cuda_flag else self.get_mask(sen_size)\n",
    "\n",
    "    def get_mask(self, sen_size) :\n",
    "        # masking tensor\n",
    "        mask_array = 1 - np.tril(np.ones((sen_size,sen_size)) , 0)\n",
    "        mask_tensor = torch.tensor(mask_array , dtype = torch.float32 , requires_grad=False)\n",
    "        mask_tensor = mask_tensor.unsqueeze(0) # shape : (1, sen_size, sen_size)\n",
    "\n",
    "        return mask_tensor\n",
    "    \n",
    "    def forward(self, in_tensor) :\n",
    "        mask_tensor = torch.maximum(in_tensor, self.mask_tensor)\n",
    "\n",
    "        return mask_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7de3f039-c5e6-4bd7-a635-f27a6017d079",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module) :\n",
    "\n",
    "    def __init__(self, pos_len, d_model, cuda_flag) :\n",
    "        super(PositionalEncoding , self).__init__()\n",
    "        self.pos_len = pos_len\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # w : weight\n",
    "        # pe : Encoding tensor\n",
    "        if cuda_flag == True :\n",
    "            self.w = torch.sqrt(torch.tensor(d_model, dtype=torch.float32, requires_grad=False)).cuda()\n",
    "            self.pe = self.get_embedding(pos_len, d_model).cuda()\n",
    "\n",
    "        else :\n",
    "            self.w = torch.sqrt(torch.tensor(d_model, dtype=torch.float32, requires_grad=False))\n",
    "            self.pe = self.get_embedding(pos_len, d_model)\n",
    "\n",
    "    # Embedding tensor : (batch_size, sen_size, embedding_dimension)\n",
    "    # Making Encoding tensor (1, sen_size, embedding_dimension)\n",
    "    def get_embedding(self, pos_len, d_model) :\n",
    "        pos_vec = torch.arange(pos_len).float()\n",
    "        pos_vec = pos_vec.unsqueeze(1)\n",
    "\n",
    "        i_vec = torch.arange(d_model).float() / 2\n",
    "        i_vec = torch.floor(i_vec) * 2\n",
    "        i_vec = i_vec.unsqueeze(0) / d_model\n",
    "        i_vec = 1 / torch.pow(1e+4 , i_vec)\n",
    "\n",
    "        em = torch.matmul(pos_vec, i_vec)\n",
    "        pe = torch.zeros(pos_len, d_model, requires_grad=False)\n",
    "\n",
    "        sin_em = torch.sin(em)\n",
    "        cos_em = torch.cos(em)\n",
    "\n",
    "        pe[:,::2] = sin_em[:,::2]\n",
    "        pe[:,1::2] = cos_em[:,1::2]\n",
    "\n",
    "        pe = pe.unsqueeze(0)\n",
    "\n",
    "        return pe\n",
    "\n",
    "    def forward(self, in_tensor) :\n",
    "        en_tensor = in_tensor * self.w + self.pe\n",
    "        \n",
    "        return en_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c5675306-fa27-4b52-9f51-76529149cb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module) :\n",
    "\n",
    "    def __init__(self, sen_size,  d_model, num_heads) :\n",
    "        super(MultiHeadAttention , self).__init__()\n",
    "        self.sen_size = sen_size # sen_size\n",
    "        self.d_model = d_model # embedidng_dim\n",
    "        self.num_heads = num_heads # head_size\n",
    "        self.depth = int(d_model / num_heads) # embedding_dim / num_heads\n",
    "\n",
    "        self.q_layer = nn.Linear(d_model , d_model)\n",
    "        self.k_layer = nn.Linear(d_model , d_model)\n",
    "        self.v_layer = nn.Linear(d_model , d_model)\n",
    "        self.o_layer = nn.Linear(d_model , d_model)\n",
    "\n",
    "        self.scale = torch.sqrt(torch.tensor(self.depth , dtype=torch.float32 , requires_grad=False))\n",
    "        \n",
    "        self.init_param()\n",
    "\n",
    "    def split(self, tensor) :\n",
    "        tensor = torch.reshape(tensor , (-1 , self.sen_size , self.num_heads , self.depth)) # (batch_size, sen_size, num_heads, depth)\n",
    "        tensor = torch.transpose(tensor , 2 , 1) # batch_size, num_heads, sen_size, depth)\n",
    "\n",
    "        return tensor\n",
    "\n",
    "    def merge(self, tensor) :\n",
    "        tensor = torch.transpose(tensor , 2 , 1) # (batch_size, sen_size, num_heads, depth)\n",
    "        tensor = torch.reshape(tensor , (-1 , self.sen_size , self.d_model)) # (batch_size , sen_size , embedding_dim)\n",
    "\n",
    "        return tensor\n",
    "\n",
    "    def scaled_dot_production(self, q_tensor, k_tensor, v_tensor, m_tensor) :\n",
    "        q_tensor = self.split(q_tensor)\n",
    "        k_tensor = self.split(k_tensor)\n",
    "        v_tensor = self.split(v_tensor)\n",
    "        \n",
    "        k_tensor_T = torch.transpose(k_tensor , 3 , 2) # (batch_size, num_heads, depth, sen_size)\n",
    "\n",
    "        qk_tensor = torch.matmul(q_tensor , k_tensor_T) # (batch_size, num_heads, sen_size, sen_size)\n",
    "        qk_tensor /= self.scale\n",
    "\n",
    "        # pad mask tensor shape : (batch_size, 1, 1, sen_size)\n",
    "        # lookahead mask tensor shape : (batch_size, 1, sen_size, sen_size)\n",
    "        if m_tensor != None :\n",
    "            qk_tensor -= (m_tensor * 1e+6)\n",
    "\n",
    "        qk_tensor = F.softmax(qk_tensor , dim = -1)\n",
    "        att = torch.matmul(qk_tensor , v_tensor) # (batch_size, num_heads, sen_size, depth)\n",
    "\n",
    "        return att\n",
    "\n",
    "    # Xavier Initialization\n",
    "    def init_param(self) :\n",
    "        for m in self.modules() :\n",
    "            if isinstance(m,nn.Linear) :\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, q_in, k_in, v_in, m_in) :\n",
    "        q_tensor = self.q_layer(q_in)\n",
    "        k_tensor = self.k_layer(k_in)\n",
    "        v_tensor = self.v_layer(v_in)\n",
    "\n",
    "        att_tensor = self.scaled_dot_production(q_tensor , k_tensor , v_tensor , m_in)\n",
    "        att_tensor = self.merge(att_tensor)\n",
    "\n",
    "        o_tensor = self.o_layer(att_tensor)\n",
    "\n",
    "        return o_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "dea414d7-8b60-4d84-b32d-778f8ab400e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module) :\n",
    "\n",
    "    def __init__(self, hidden_size, d_model) :\n",
    "        super(FeedForward , self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        # relu activation and input, output dim are same\n",
    "        self.ff = nn.Sequential(nn.Linear(d_model , hidden_size), \n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(hidden_size , d_model))\n",
    "        self.init_param()\n",
    "                \n",
    "    # He Initialization\n",
    "    def init_param(self) :\n",
    "        gain = 2 ** (1/2)\n",
    "        for m in self.modules() :\n",
    "            if isinstance(m , nn.Linear) :\n",
    "                nn.init.kaiming_normal_(m.weight , gain)\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self , in_tensor) :\n",
    "        o_tensor = self.ff(in_tensor)\n",
    "\n",
    "        return o_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fd374424-a093-4146-b5ba-60201260dd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(nn.Module) :\n",
    "\n",
    "    def __init__(self, layer_size, sen_size, v_size, d_model, num_heads, hidden_size, \n",
    "                 drop_rate, norm_rate, cuda_flag) :\n",
    "        super(TransformerEncoder , self).__init__()\n",
    "        self.layer_size = layer_size\n",
    "        self.sen_size = sen_size\n",
    "        self.v_size = v_size\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.hidden_size = hidden_size\n",
    "        self.drop_rate = drop_rate\n",
    "        self.norm_rate = norm_rate\n",
    "\n",
    "        self.em = nn.Embedding(num_embeddings=v_size, embedding_dim=d_model, padding_idx=0) # embedding\n",
    "        self.pos = PositionalEncoding(sen_size, d_model, cuda_flag) # positional encoding\n",
    "        self.pad = PaddingMask(sen_size) # masking\n",
    "        \n",
    "        self.mha_layer = nn.ModuleList()\n",
    "        self.ff_layer = nn.ModuleList()\n",
    "\n",
    "        self.drop_layer = nn.Dropout(drop_rate)\n",
    "        self.norm_layer = nn.LayerNorm(d_model , eps=norm_rate)\n",
    "\n",
    "        for i in range(layer_size) :\n",
    "            self.mha_layer.append(MultiHeadAttention(sen_size , d_model , num_heads))\n",
    "            self.ff_layer.append(FeedForward(hidden_size , d_model))\n",
    "\n",
    "        self.init_param()\n",
    "            \n",
    "    def init_param(self) :\n",
    "        nn.init.normal_(self.em.weight, mean=0.0, std=0.1)\n",
    "            \n",
    "    def forward_block(self, i, in_tensor, m_tensor) :\n",
    "        mha_tensor = self.mha_layer[i](in_tensor , in_tensor , in_tensor , m_tensor)\n",
    "        mha_tensor = self.drop_layer(mha_tensor)\n",
    "        h_tensor = self.norm_layer(in_tensor + mha_tensor)\n",
    "\n",
    "        ff_tensor = self.ff_layer[i](h_tensor)\n",
    "        ff_tensor = self.drop_layer(ff_tensor)\n",
    "        o_tensor = self.norm_layer(h_tensor + ff_tensor)\n",
    "\n",
    "        return o_tensor\n",
    "\n",
    "    def forward(self, in_tensor) :\n",
    "        pad_mask = self.pad(in_tensor)\n",
    "        em_tensor = self.em(in_tensor)\n",
    "        en_tensor = self.pos(em_tensor)\n",
    "        \n",
    "        tensor_ptr = en_tensor\n",
    "        for i in range(self.layer_size) :\n",
    "            tensor_ptr = self.forward_block(i, tensor_ptr, pad_mask)\n",
    "        \n",
    "        return tensor_ptr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a1db92ae-70b8-4580-83b6-ece97c4257a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDecoder(nn.Module) :\n",
    "\n",
    "    def __init__(self, layer_size, sen_size, v_size, d_model, num_heads, hidden_size, \n",
    "                 drop_rate, norm_rate, cuda_flag) :\n",
    "        super(TransformerDecoder , self).__init__()\n",
    "        self.layer_size = layer_size\n",
    "        self.sen_size = sen_size\n",
    "        self.v_size = v_size\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.hidden_size = hidden_size\n",
    "        self.drop_rate = drop_rate\n",
    "        self.norm_rate = norm_rate\n",
    "        \n",
    "        self.em = nn.Embedding(num_embeddings=v_size, embedding_dim=d_model, padding_idx=0) # embedding\n",
    "        self.pos = PositionalEncoding(sen_size, d_model, cuda_flag) # positional encoding\n",
    "        self.pad = PaddingMask(sen_size) # padding masking\n",
    "        self.lookahead = LookAheadMask(sen_size , cuda_flag) # lookahead masking\n",
    "        \n",
    "        self.masked_mha_layer = nn.ModuleList()\n",
    "        self.mha_layer = nn.ModuleList()\n",
    "        self.ff_layer = nn.ModuleList()\n",
    "\n",
    "        self.drop_layer = nn.Dropout(drop_rate)\n",
    "        self.norm_layer = nn.LayerNorm(d_model , eps=norm_rate)\n",
    "        \n",
    "        self.o_layer = nn.Linear(d_model, v_size)\n",
    "\n",
    "        for i in range(layer_size) :\n",
    "            self.masked_mha_layer.append(MultiHeadAttention(sen_size , d_model , num_heads))\n",
    "            self.mha_layer.append(MultiHeadAttention(sen_size , d_model , num_heads))\n",
    "            self.ff_layer.append(FeedForward(hidden_size , d_model))\n",
    "    \n",
    "        self.init_param()\n",
    "        \n",
    "    def init_param(self) :\n",
    "        nn.init.normal_(self.em.weight, mean=0.0, std=0.1)\n",
    "        \n",
    "        nn.init.xavier_normal_(self.o_layer.weight, gain=1.0)\n",
    "        nn.init.zeros_(self.o_layer.bias)\n",
    "            \n",
    "    def forward_block(self, i, in_tensor, en_out_tensor, padding_mask, lookahead_mask) :\n",
    "        # query : in_tensor\n",
    "        # key : in_tensor \n",
    "        # value : in_tensor \n",
    "        # mask ; look ahead mask\n",
    "        m_mha_tensor = self.masked_mha_layer[i](in_tensor , in_tensor , in_tensor , lookahead_mask)\n",
    "        m_mha_tensor = self.drop_layer(m_mha_tensor)\n",
    "        h_tensor = self.norm_layer(in_tensor + m_mha_tensor)\n",
    "\n",
    "        # query : output of masked multihead attention\n",
    "        # key : encoder output , \n",
    "        # value : encoder output , \n",
    "        # mask ; padding mask\n",
    "        mha_tensor = self.mha_layer[i](h_tensor, en_out_tensor, en_out_tensor, padding_mask)\n",
    "        mha_tensor = self.drop_layer(mha_tensor)\n",
    "        a_tensor = self.norm_layer(h_tensor+mha_tensor)\n",
    "\n",
    "        ff_tensor = self.ff_layer[i](a_tensor)\n",
    "        ff_tensor = self.drop_layer(ff_tensor)\n",
    "        o_tensor = self.norm_layer(a_tensor+ff_tensor)\n",
    "\n",
    "        return o_tensor\n",
    "\n",
    "    def forward(self, in_tensor, en_out_tensor) :\n",
    "        pad_mask = self.pad(in_tensor)\n",
    "        lookahead_mask = self.lookahead(pad_mask)\n",
    "        em_tensor = self.em(in_tensor)\n",
    "        de_tensor = self.pos(em_tensor)\n",
    "        \n",
    "        tensor_ptr = de_tensor\n",
    "        for i in range(self.layer_size) :\n",
    "            tensor_ptr = self.forward_block(i, tensor_ptr, en_out_tensor, pad_mask, lookahead_mask)\n",
    "        o_tensor = self.o_layer(tensor_ptr)\n",
    "        \n",
    "        return o_tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41111527-b748-4ea7-8d28-38fc98ea6de1",
   "metadata": {},
   "source": [
    "## Model Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "34e2ebd6-6db0-44b2-8197-88c8a768da97",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_v_size = en_encoder.get_size()\n",
    "kor_v_size = kor_encoder.get_size()\n",
    "\n",
    "# transformer model(big)\n",
    "layer_size = 6\n",
    "sen_size = max_len\n",
    "d_model = 512\n",
    "num_heads = 8\n",
    "h_size = 2048\n",
    "drop_rate = 1e-1\n",
    "norm_rate = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4a32cc66-d3cd-4dda-829d-03ceb495d9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = TransformerEncoder(layer_size, sen_size, kor_v_size, \n",
    "                             d_model, num_heads, h_size, drop_rate, norm_rate, use_cuda).to(device)\n",
    "\n",
    "decoder = TransformerDecoder(layer_size, sen_size, en_v_size, \n",
    "                             d_model, num_heads, h_size, drop_rate, norm_rate, use_cuda).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7beeb5a7-fcdf-4cf4-9685-351d1ccb1605",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "605b9618-1a19-4fb6-aca1-eebc7ff3392c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dumb_lr = 1e-4 # no meaning\n",
    "\n",
    "epoch_size = int(100000 / len(train_loader))\n",
    "warmup_steps = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ff579e67-7775-4655-8ded-a26de77216a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def schedule_fn(epoch, d_model, dumb_lr) :\n",
    "    step_num = epoch + 1\n",
    "    val1 = d_model ** (-0.5)\n",
    "    \n",
    "    arg1 = step_num ** (-0.5)\n",
    "    arg2 = (warmup_steps ** (-1.5)) * step_num\n",
    "    \n",
    "    val2 = min(arg1 , arg2) \n",
    "    return (val1 * val2) / dumb_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "57880e66-2a15-473a-b3f0-dac6a4f3c5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_param = chain(encoder.parameters(), decoder.parameters())\n",
    "\n",
    "optimizer = optim.Adam(tf_param, lr=dumb_lr, betas=(0.9,0.98), eps=1e-9)\n",
    "scheduler = optim.lr_scheduler.LambdaLR(optimizer, \n",
    "                                        lr_lambda = lambda epoch: schedule_fn(epoch, d_model, dumb_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd58022f-68c0-48cb-a5aa-0abeee8c04e0",
   "metadata": {},
   "source": [
    "## Acc & Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7674d10b-b778-4e8d-8968-c7e97c397210",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_fn(y_output , y_label) :\n",
    "    \n",
    "    y_arg = torch.argmax(y_output, dim=-1)\n",
    "    y_acc = (y_arg == y_label).float()\n",
    "\n",
    "    y_acc = torch.mean(y_acc)\n",
    "    \n",
    "    return y_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "60f934ae-b533-4c39-b58d-76a4275ecee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fb6adb-fc5d-4eaa-a93b-eaf41c3a0796",
   "metadata": {},
   "source": [
    "## Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "55dc8431-65d7-4f84-bcc7-b0c2a5fede3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('./Log/runs/transformer/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0a6849-f33f-455c-8d41-2177c5137e4d",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "818615d4-75e6-46a2-bf30-a52a70ac4651",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_loss = np.inf\n",
    "stop_count = 0\n",
    "log_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "14b1a8fe-0ccf-4867-b97b-1484de12e7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def progressLearning(value, endvalue, loss , acc , bar_length=50):\n",
    "    percent = float(value + 1) / endvalue\n",
    "    arrow = '-' * int(round(percent * bar_length)-1) + '>'\n",
    "    spaces = ' ' * (bar_length - len(arrow))\n",
    "\n",
    "    sys.stdout.write(\"\\rPercent: [{0}] {1}/{2} \\t Loss : {3:.3f} , Acc : {4:.3f}\".format(arrow + spaces, value+1 , endvalue , loss , acc))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6dc38a61-8290-4ce8-a49c-66f2d382e14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, test_loader) :\n",
    "    with torch.no_grad() :\n",
    "        encoder.eval()\n",
    "        decoder.eval()\n",
    "        \n",
    "        loss_eval = 0.0\n",
    "        acc_eval = 0.0\n",
    "        \n",
    "        for data in test_loader :\n",
    "            en_in = data['encoder_in'].long().to(device)\n",
    "            de_in = data['decoder_in'].long().to(device)\n",
    "            de_label = data['decoder_out'].long().to(device)\n",
    "            \n",
    "            de_label = data['decoder_out'].long().to(device)\n",
    "            de_label = torch.reshape(de_label, (-1,))\n",
    "            \n",
    "            en_output = encoder(en_in)\n",
    "            de_output = decoder(de_in, en_output)\n",
    "            de_output = torch.reshape(de_output, (-1,en_v_size))\n",
    "            \n",
    "            loss_eval += loss_fn(de_output , de_label)\n",
    "            acc_eval += acc_fn(de_output , de_label)\n",
    "\n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "\n",
    "        loss_eval /= len(test_loader)\n",
    "        acc_eval /= len(test_loader)\n",
    "        \n",
    "    return loss_eval , acc_eval  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca61e80-5052-4c67-8e04-aff681fc8374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 \t Learning Rate : 1.746928e-07\n",
      "Percent: [------------------------------------------------->] 1125/1125 \t Loss : 6.877 , Acc : 0.359\n",
      "Val Loss : 6.707 \t Val Accuracy : 0.364\n",
      "\n",
      "Epoch : 1 \t Learning Rate : 3.493856e-07\n",
      "Percent: [---->                                             ] 111/1125 \t Loss : 6.668 , Acc : 0.372"
     ]
    }
   ],
   "source": [
    "for epoch in range(epoch_size) :\n",
    "    idx = 0\n",
    "    lr_idx = optimizer.param_groups[0]['lr']\n",
    "    print('Epoch : %d \\t Learning Rate : %e' %(epoch , lr_idx))\n",
    "\n",
    "    for data in train_loader :\n",
    "        en_in = data['encoder_in'].long().to(device)\n",
    "        de_in = data['decoder_in'].long().to(device)\n",
    "        \n",
    "        de_label = data['decoder_out'].long().to(device)\n",
    "        de_label = torch.reshape(de_label, (-1,))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        en_output = encoder(en_in)\n",
    "        de_output = decoder(de_in, en_output)\n",
    "        de_output = torch.reshape(de_output, (-1,en_v_size))\n",
    "\n",
    "        loss = loss_fn(de_output , de_label)\n",
    "        acc = acc_fn(de_output , de_label)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        progressLearning(idx, len(train_loader), loss.item(), acc.item())\n",
    "\n",
    "        if (idx + 1) % 10 == 0 :\n",
    "            writer.add_scalar('train/loss' , loss.item() , log_count)\n",
    "            writer.add_scalar('train/acc' , acc.item() , log_count)\n",
    "            log_count += 1\n",
    "        \n",
    "        idx += 1\n",
    "\n",
    "    val_loss, val_acc = evaluate(encoder, decoder, val_loader)\n",
    "        \n",
    "    writer.add_scalar('test/loss' , val_loss.item() , epoch)\n",
    "    writer.add_scalar('test/acc' , val_acc.item() , epoch)\n",
    "    \n",
    "    if val_loss < min_loss :\n",
    "        min_loss = val_loss\n",
    "        torch.save({'epoch' : (epoch) ,  \n",
    "                    'encoder_state_dict' : encoder.state_dict() , \n",
    "                    'decoder_state_dict' : decoder.state_dict() , \n",
    "                    'loss' : val_loss.item() , \n",
    "                    'acc' : val_acc.item()} , \n",
    "                    f'./Model/checkpoint_transformer.pt')        \n",
    "        stop_count = 0 \n",
    "    else :\n",
    "        stop_count += 1\n",
    "        if stop_count >= 5 :      \n",
    "            print('\\nTraining Early Stopped')\n",
    "            break\n",
    "            \n",
    "    scheduler.step()\n",
    "    print('\\nVal Loss : %.3f \\t Val Accuracy : %.3f\\n' %(val_loss, val_acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8df83e-4df6-47bd-8e6b-883409dea631",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3d1d6e2c-f1c1-4ed7-902d-0a0d457b708a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Translation :\n",
    "    \n",
    "    def __init__(self, sen_size, start_tok, en_tok, encoder, decoder , alpha=0.6) :\n",
    "        \n",
    "        self.sen_size = sen_size\n",
    "        self.en_tok = en_tok\n",
    "        \n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        \n",
    "        self.encoder = encoder.eval()\n",
    "        self.decoder = decoder.eval()\n",
    "        \n",
    "    def convert(self, in_seq) :\n",
    "        in_vec = np.array(in_seq)\n",
    "        in_vec = np.pad(in_vec, [0,self.sen_size-len(in_vec)])\n",
    "        \n",
    "        in_tensor = torch.tensor(in_vec, dtype=torch.long, requires_grad=False).unsqueeze(0)\n",
    "        in_tensor = in_tensor.to(device)\n",
    "        \n",
    "        return in_tensor\n",
    "    \n",
    "    def select(self, sen_list, beam_size) :\n",
    "        sen_list.sort(key=lambda x:x[1], reverse=True)\n",
    "        sen_sel = sen_list[:beam_size]\n",
    "        \n",
    "        return sen_sel\n",
    "    \n",
    "    def check_end(self, sen_list) :\n",
    "        flag = True\n",
    "        for sen in sen_list :\n",
    "            if sen[2] == False :\n",
    "                return False\n",
    "            \n",
    "        return True\n",
    "    \n",
    "    def get_penalty(self, token_next) :\n",
    "        token_len = len(token_next)\n",
    "        \n",
    "        num = np.power((5+token_len), self.alpha)\n",
    "        denom = np.power((5+1), self.alpha)\n",
    "        \n",
    "        penalty = num / denom\n",
    "        \n",
    "        return penalty\n",
    "        \n",
    "    def translate(self, in_seq , beam_size=5) :\n",
    "        en_in = self.convert(in_seq)\n",
    "        en_out = self.encoder(en_in)\n",
    "        \n",
    "        sen_list = [([start_tok],0.0,False)]\n",
    "        idx = 0\n",
    "        \n",
    "        while(idx<self.sen_size) :\n",
    "            sen_ptr = []\n",
    "            \n",
    "            if self.check_end(sen_list) :\n",
    "                break\n",
    "            \n",
    "            for i in range(len(sen_list)) :\n",
    "                tok_list, val, end_flag = sen_list[i]\n",
    "                \n",
    "                if end_flag == True : \n",
    "                    sen_ptr.append(sen_list[i])\n",
    "                    continue\n",
    "                \n",
    "                de_in = self.convert(tok_list)\n",
    "                de_out = self.decoder(de_in, en_out).squeeze(0)\n",
    "                de_prob = F.softmax(de_out, dim=-1)\n",
    "                de_log = torch.log(de_prob + 1e-30)\n",
    "            \n",
    "                de_val, de_arg = torch.sort(de_log, dim=-1, descending=True)\n",
    "                \n",
    "                de_val_idx = de_val[idx]\n",
    "                de_arg_idx = de_arg[idx]\n",
    "\n",
    "                for j in range(beam_size) :        \n",
    "                    val_next = val + de_val_idx[j].item()\n",
    "                    token_next = de_arg_idx[j].item()\n",
    "                    flag_next = True if token_next == self.en_tok else False\n",
    "                    \n",
    "                    tok_list_next = tok_list + [token_next]\n",
    "                    penalty = self.get_penalty(tok_list_next)\n",
    "                    \n",
    "                    val_next /= penalty\n",
    "                    sen_ptr.append((tok_list_next, val_next, flag_next))\n",
    "                \n",
    "            sen_list = self.select(sen_ptr, beam_size)\n",
    "            \n",
    "            idx += 1\n",
    "            \n",
    "        pred_sen = sen_list[0][0]\n",
    "            \n",
    "        return pred_sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02acfba4-265a-4f68-af0a-c7f1d6aa8164",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8453b0fb-e017-44df-8f73-c2bb66ccdc47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8dbdfd2-22a1-4673-b302-08f9c9d22e1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
