{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c3d8a4a-9511-4729-86a8-685dd81594d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfc08618-d053-4353-a3b1-cfa33c352726",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader , Subset, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e77c592a-a772-4a15-ab5a-7dd47cb86377",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58045956-17ec-4294-bf72-204ffca23c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "921564bf-6b90-47d1-a53e-1e95d8a727df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c55ae445-da83-4f78-a774-4cb5105a8d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cde95a9-1a7b-431c-9749-953788967078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from preprocessor.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "import preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "914f4b77-f37b-4cd5-96fa-94ea06b4ba2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56664b34-2f11-4b8a-a110-ab4035443932",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from konlpy.tag import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9b02ee3-d796-436f-b597-b099f11c7e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mecab = Mecab()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67a2d84-b00e-43b5-9e15-e80c215412ee",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7302e5d3-12d0-49e8-8613-0c5b2230fb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = '../../Data/'\n",
    "data = pd.read_excel(dir_path + '한국어_대화체_번역.xlsx' , engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4da2f22-ec0d-428f-af99-7b5989e7befc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>원문</th>\n",
       "      <th>번역문</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>이번 신제품 출시에 대한 시장의 반응은 어떤가요?</td>\n",
       "      <td>How is the market's reaction to the newly rele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>판매량이 지난번 제품보다 빠르게 늘고 있습니다.</td>\n",
       "      <td>The sales increase is faster than the previous...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>그렇다면 공장에 연락해서 주문량을 더 늘려야겠네요.</td>\n",
       "      <td>Then, we'll have to call the manufacturer and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>네, 제가 연락해서 주문량을 2배로 늘리겠습니다.</td>\n",
       "      <td>Sure, I'll make a call and double the volume o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>지난 회의 마지막에 논의했던 안건을 다시 볼까요?</td>\n",
       "      <td>Shall we take a look at the issues we discusse...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             원문  \\\n",
       "0   이번 신제품 출시에 대한 시장의 반응은 어떤가요?   \n",
       "1    판매량이 지난번 제품보다 빠르게 늘고 있습니다.   \n",
       "2  그렇다면 공장에 연락해서 주문량을 더 늘려야겠네요.   \n",
       "3   네, 제가 연락해서 주문량을 2배로 늘리겠습니다.   \n",
       "4   지난 회의 마지막에 논의했던 안건을 다시 볼까요?   \n",
       "\n",
       "                                                 번역문  \n",
       "0  How is the market's reaction to the newly rele...  \n",
       "1  The sales increase is faster than the previous...  \n",
       "2  Then, we'll have to call the manufacturer and ...  \n",
       "3  Sure, I'll make a call and double the volume o...  \n",
       "4  Shall we take a look at the issues we discusse...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['원문','번역문']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21eb953-8b85-4734-a914-0f25b093e4ad",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07550a9f-3fcc-4248-a690-b1274e82bb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_data = data['번역문']\n",
    "kor_data = data['원문']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7cc61f2f-eb6f-4262-8291-1c85987339c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:13<00:00, 7323.00it/s]\n"
     ]
    }
   ],
   "source": [
    "en_vs = preprocessor.VocabSet(word_tokenize, th=2)\n",
    "en_tokens = en_vs.tokens(en_data)\n",
    "en_encoder = preprocessor.Encoder(en_data, word_tokenize, en_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66d0537a-d263-4af0-bf41-5ad3b3c52951",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:14<00:00, 7051.86it/s]\n"
     ]
    }
   ],
   "source": [
    "en_encoded = en_encoder.encode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c3dbb08-162f-4586-8e23-9874eae1c29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:08<00:00, 12264.39it/s]\n"
     ]
    }
   ],
   "source": [
    "kor_vs = preprocessor.VocabSet(mecab.morphs, th=2)\n",
    "kor_tokens = kor_vs.tokens(kor_data)\n",
    "kor_encoder = preprocessor.Encoder(kor_data, mecab.morphs, kor_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ec7a5ad-cc8a-4404-80e5-cb91441eb4ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:08<00:00, 11593.53it/s]\n"
     ]
    }
   ],
   "source": [
    "kor_encoded = kor_encoder.encode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01992504-aea2-46d6-a38f-391a7f1a2e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9e94be-38c0-401e-8afd-c66b5241ea7b",
   "metadata": {},
   "source": [
    "## Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c7448b2-6fbf-41e6-801d-06255d3b6b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoderDataset(Dataset) :\n",
    "\n",
    "    def __init__(self, en_list, de_list, sen_size, val_ratio=0.1) :\n",
    "        super(EncoderDecoderDataset , self).__init__()\n",
    "        self.en_in = pad_sequences(en_list, maxlen=sen_size, padding='post')\n",
    "        \n",
    "        de_array = pad_sequences(de_list, maxlen=sen_size+1, padding='post')\n",
    "        self.de_in = de_array[:,:-1]\n",
    "        self.de_out = de_array[:,1:]\n",
    "        \n",
    "        self.val_ratio = val_ratio\n",
    "\n",
    "    def __len__(self) :\n",
    "        return len(self.en_in)\n",
    "\n",
    "    def __getitem__(self , idx) :\n",
    "        en_in_idx = self.en_in[idx]\n",
    "        de_in_idx = self.de_in[idx]\n",
    "        de_out_idx = self.de_out[idx]\n",
    "        \n",
    "        return {'encoder_in' : en_in_idx, 'decoder_in' : de_in_idx, 'decoder_out' : de_out_idx}\n",
    "    \n",
    "    def split_dataset(self) :\n",
    "        n_val = int(len(self) * self.val_ratio)\n",
    "        n_train = len(self) - n_val\n",
    "        train_set, val_set = random_split(self, [n_train, n_val])\n",
    "        \n",
    "        return train_set, val_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "97968ac0-37b9-4efa-8d02-15bc5a70b4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = EncoderDecoderDataset(kor_encoded, en_encoded, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa1de75c-2951-4ebf-9887-a5b3e496cd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, val_set = dataset.split_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dc6ab97a-1554-4ab9-ae89-06b06730970d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 60\n",
    "\n",
    "train_loader = DataLoader(train_set ,\n",
    "                          batch_size = batch_size,\n",
    "                          num_workers = 4,\n",
    "                          shuffle = True,\n",
    "                          drop_last = True)\n",
    "\n",
    "val_loader = DataLoader(val_set ,\n",
    "                        batch_size = 100,\n",
    "                        num_workers = 4,\n",
    "                        shuffle = False,\n",
    "                        drop_last = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c4e0c2-4c37-4022-a513-432666621d0d",
   "metadata": {},
   "source": [
    "## Device & Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "122ff02d-45fe-42f2-8880-c4d08b0629c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "random.seed(20210906)\n",
    "torch.cuda.manual_seed_all(20210906)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed26eb4-4524-4c40-9421-62d25278837d",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8385ddf1-9fc9-483a-ab20-fca7d280ca20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PaddingMask(nn.Module) :\n",
    "\n",
    "    def __init__(self, sen_size) :\n",
    "        super(PaddingMask , self).__init__() \n",
    "        self.sen_size = sen_size\n",
    "    \n",
    "    def forward(self, in_tensor) :\n",
    "        batch_size = in_tensor.shape[0]\n",
    "        # mask tensor which element is 0.0\n",
    "        flag_tensor = torch.where(in_tensor == 0.0 , 1.0 , 0.0)\n",
    "        # shape : (batch_size, 1, 1, sen_size)\n",
    "        flag_tensor = torch.reshape(flag_tensor , (batch_size, 1, 1, self.sen_size)) \n",
    "        \n",
    "        return flag_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "00ca3d19-98ab-46c6-aaa3-2404596ac905",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LookAheadMask(nn.Module) :\n",
    "\n",
    "    def __init__(self, sen_size, cuda_flag) :\n",
    "        super(LookAheadMask, self).__init__() \n",
    "        self.sen_size = sen_size\n",
    "        self.mask_tensor = self.get_mask(sen_size).cuda() if cuda_flag else self.get_mask(sen_size)\n",
    "\n",
    "    def get_mask(self, sen_size) :\n",
    "        # masking tensor\n",
    "        mask_array = 1 - np.tril(np.ones((sen_size,sen_size)) , 0)\n",
    "        mask_tensor = torch.tensor(mask_array , dtype = torch.float32 , requires_grad=False)\n",
    "        mask_tensor = mask_tensor.unsqueeze(0) # shape : (1, sen_size, sen_size)\n",
    "\n",
    "        return mask_tensor\n",
    "    \n",
    "    def forward(self, in_tensor) :\n",
    "        mask_tensor = torch.maximum(in_tensor, self.mask_tensor)\n",
    "\n",
    "        return mask_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7de3f039-c5e6-4bd7-a635-f27a6017d079",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module) :\n",
    "\n",
    "    def __init__(self, pos_len, d_model, cuda_flag) :\n",
    "        super(PositionalEncoding , self).__init__()\n",
    "        self.pos_len = pos_len\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # w : weight\n",
    "        # pe : Encoding tensor\n",
    "        if cuda_flag == True :\n",
    "            self.w = torch.sqrt(torch.tensor(d_model, dtype=torch.float32, requires_grad=False)).cuda()\n",
    "            self.pe = self.get_embedding(pos_len, d_model).cuda()\n",
    "\n",
    "        else :\n",
    "            self.w = torch.sqrt(torch.tensor(d_model, dtype=torch.float32, requires_grad=False))\n",
    "            self.pe = self.get_embedding(pos_len, d_model)\n",
    "\n",
    "    # Embedding tensor : (batch_size, sen_size, embedding_dimension)\n",
    "    # Making Encoding tensor (1, sen_size, embedding_dimension)\n",
    "    def get_embedding(self, pos_len, d_model) :\n",
    "        pos_vec = torch.arange(pos_len).float()\n",
    "        pos_vec = pos_vec.unsqueeze(1)\n",
    "\n",
    "        i_vec = torch.arange(d_model).float() / 2\n",
    "        i_vec = torch.floor(i_vec) * 2\n",
    "        i_vec = i_vec.unsqueeze(0) / d_model\n",
    "        i_vec = 1 / torch.pow(1e+4 , i_vec)\n",
    "\n",
    "        em = torch.matmul(pos_vec, i_vec)\n",
    "        pe = torch.zeros(pos_len, d_model, requires_grad=False)\n",
    "\n",
    "        sin_em = torch.sin(em)\n",
    "        cos_em = torch.cos(em)\n",
    "\n",
    "        pe[:,::2] = sin_em[:,::2]\n",
    "        pe[:,1::2] = cos_em[:,1::2]\n",
    "\n",
    "        pe = pe.unsqueeze(0)\n",
    "\n",
    "        return pe\n",
    "\n",
    "    def forward(self, in_tensor) :\n",
    "        en_tensor = in_tensor * self.w + self.pe\n",
    "        \n",
    "        return en_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c5675306-fa27-4b52-9f51-76529149cb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module) :\n",
    "\n",
    "    def __init__(self, sen_size,  d_model, num_heads) :\n",
    "        super(MultiHeadAttention , self).__init__()\n",
    "        self.sen_size = sen_size # sen_size\n",
    "        self.d_model = d_model # embedidng_dim\n",
    "        self.num_heads = num_heads # head_size\n",
    "        self.depth = int(d_model / num_heads) # embedding_dim / num_heads\n",
    "\n",
    "        self.q_layer = nn.Linear(d_model , d_model)\n",
    "        self.k_layer = nn.Linear(d_model , d_model)\n",
    "        self.v_layer = nn.Linear(d_model , d_model)\n",
    "        self.o_layer = nn.Linear(d_model , d_model)\n",
    "\n",
    "        self.scale = torch.sqrt(torch.tensor(self.depth , dtype=torch.float32 , requires_grad=False))\n",
    "        \n",
    "        self.init_param()\n",
    "\n",
    "    def split(self, tensor) :\n",
    "        tensor = torch.reshape(tensor , (-1 , self.sen_size , self.num_heads , self.depth)) # (batch_size, sen_size, num_heads, depth)\n",
    "        tensor = torch.transpose(tensor , 2 , 1) # batch_size, num_heads, sen_size, depth)\n",
    "\n",
    "        return tensor\n",
    "\n",
    "    def merge(self, tensor) :\n",
    "        tensor = torch.transpose(tensor , 2 , 1) # (batch_size, sen_size, num_heads, depth)\n",
    "        tensor = torch.reshape(tensor , (-1 , self.sen_size , self.d_model)) # (batch_size , sen_size , embedding_dim)\n",
    "\n",
    "        return tensor\n",
    "\n",
    "    def scaled_dot_production(self, q_tensor, k_tensor, v_tensor, m_tensor) :\n",
    "        q_tensor = self.split(q_tensor)\n",
    "        k_tensor = self.split(k_tensor)\n",
    "        v_tensor = self.split(v_tensor)\n",
    "        \n",
    "        k_tensor_T = torch.transpose(k_tensor , 3 , 2) # (batch_size, num_heads, depth, sen_size)\n",
    "\n",
    "        qk_tensor = torch.matmul(q_tensor , k_tensor_T) # (batch_size, num_heads, sen_size, sen_size)\n",
    "        qk_tensor /= self.scale\n",
    "\n",
    "        # pad mask tensor shape : (batch_size, 1, 1, sen_size)\n",
    "        # lookahead mask tensor shape : (batch_size, 1, sen_size, sen_size)\n",
    "        if m_tensor != None :\n",
    "            qk_tensor -= (m_tensor * 1e+6)\n",
    "\n",
    "        qk_tensor = F.softmax(qk_tensor , dim = -1)\n",
    "        att = torch.matmul(qk_tensor , v_tensor) # (batch_size, num_heads, sen_size, depth)\n",
    "\n",
    "        return att\n",
    "\n",
    "    # Xavier Initialization\n",
    "    def init_param(self) :\n",
    "        for m in self.modules() :\n",
    "            if isinstance(m,nn.Linear) :\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, q_in, k_in, v_in, m_in) :\n",
    "        q_tensor = self.q_layer(q_in)\n",
    "        k_tensor = self.k_layer(k_in)\n",
    "        v_tensor = self.v_layer(v_in)\n",
    "\n",
    "        att_tensor = self.scaled_dot_production(q_tensor , k_tensor , v_tensor , m_in)\n",
    "        att_tensor = self.merge(att_tensor)\n",
    "\n",
    "        o_tensor = self.o_layer(att_tensor)\n",
    "\n",
    "        return o_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dea414d7-8b60-4d84-b32d-778f8ab400e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module) :\n",
    "\n",
    "    def __init__(self, hidden_size, d_model) :\n",
    "        super(FeedForward , self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        # relu activation and input, output dim are same\n",
    "        self.ff = nn.Sequential(nn.Linear(d_model , hidden_size), \n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(hidden_size , d_model))\n",
    "\n",
    "        self.init_param()\n",
    "                \n",
    "    # He Initialization\n",
    "    def init_param(self) :\n",
    "        gain = 2 ** (1/2)\n",
    "        \n",
    "        for m in self.modules() :\n",
    "            if isinstance(m , nn.Linear) :\n",
    "                nn.init.kaiming_normal_(m.weight , gain)\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self , in_tensor) :\n",
    "        o_tensor = self.ff(in_tensor)\n",
    "\n",
    "        return o_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fd374424-a093-4146-b5ba-60201260dd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module) :\n",
    "\n",
    "    def __init__(self, layer_size, sen_size, d_model, num_heads, hidden_size, drop_rate, norm_rate, cuda_flag) :\n",
    "        super(Encoder , self).__init__()\n",
    "        self.layer_size = layer_size\n",
    "        self.sen_size = sen_size\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.mha_layer = nn.ModuleList()\n",
    "        self.ff_layer = nn.ModuleList()\n",
    "        self.drop_layer = nn.Dropout(drop_rate)\n",
    "        self.norm_layer = nn.LayerNorm(d_model , eps=norm_rate)\n",
    "\n",
    "        for i in range(layer_size) :\n",
    "            # multihead attention layer\n",
    "            mha_idx = MultiHeadAttention(sen_size , d_model , num_heads)\n",
    "            self.mha_layer.append(mha_idx)\n",
    "            \n",
    "            # feedforward layer\n",
    "            ff_idx = FeedForward(hidden_size , d_model)\n",
    "            self.ff_layer.append(ff_idx)\n",
    "\n",
    "    def forward_block(self, i, in_tensor, pad_tensor) :\n",
    "        # query : encoder input\n",
    "        # key : encoder input \n",
    "        # value : encoder input\n",
    "        # mask ; pad_tensor of encoder input\n",
    "        mha_tensor = self.mha_layer[i](in_tensor , in_tensor , in_tensor , pad_tensor)\n",
    "        mha_tensor = self.drop_layer(mha_tensor)\n",
    "        h_tensor = self.norm_layer(in_tensor + mha_tensor)\n",
    "\n",
    "        ff_tensor = self.ff_layer[i](h_tensor)\n",
    "        ff_tensor = self.drop_layer(ff_tensor)\n",
    "        o_tensor = self.norm_layer(h_tensor + ff_tensor)\n",
    "\n",
    "        return o_tensor\n",
    "\n",
    "    def forward(self , in_tensor , pad_tensor) :\n",
    "        tensor_ptr = in_tensor\n",
    "\n",
    "        for i in range(self.layer_size) :\n",
    "            tensor_ptr = self.forward_block(i , tensor_ptr , pad_tensor)\n",
    "        \n",
    "        return tensor_ptr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a1db92ae-70b8-4580-83b6-ece97c4257a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module) :\n",
    "\n",
    "    def __init__(self, layer_size, sen_size, d_model, num_heads, hidden_size, drop_rate, norm_rate, cuda_flag) :\n",
    "        super(Decoder , self).__init__()\n",
    "        self.layer_size = layer_size\n",
    "        self.sen_size = sen_size\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.m_mha_layer = nn.ModuleList()\n",
    "        self.mha_layer = nn.ModuleList()\n",
    "        self.ff_layer = nn.ModuleList()\n",
    "\n",
    "        self.drop_layer = nn.Dropout(drop_rate)\n",
    "        self.norm_layer = nn.LayerNorm(d_model , eps=norm_rate)\n",
    "\n",
    "        self.la_mask = LookAheadMask(sen_size , cuda_flag)\n",
    "\n",
    "        for i in range(layer_size) :\n",
    "            m_mha_idx = MultiHeadAttention(sen_size , d_model , num_heads)\n",
    "            # masked multihead attention layer\n",
    "            self.m_mha_layer.append(m_mha_idx)\n",
    "\n",
    "            mha_idx = MultiHeadAttention(sen_size , d_model , num_heads)\n",
    "            # multihead attention layer\n",
    "            self.mha_layer.append(mha_idx)\n",
    "\n",
    "            ff_idx = FeedForward(hidden_size , d_model)\n",
    "            # feedforward layer\n",
    "            self.ff_layer.append(ff_idx)\n",
    "\n",
    "    def forward_block(self, i, in_tensor, en_out_tensor, pad_tensor, mask_tensor) :\n",
    "        # query : in_tensor\n",
    "        # key : in_tensor \n",
    "        # value : in_tensor \n",
    "        # mask ; look ahead mask\n",
    "        m_mha_tensor = self.m_mha_layer[i](in_tensor , in_tensor , in_tensor , mask_tensor)\n",
    "        m_mha_tensor = self.drop_layer(m_mha_tensor)\n",
    "        h_tensor = self.norm_layer(in_tensor + m_mha_tensor)\n",
    "\n",
    "        # query : output of masked multihead attention\n",
    "        # key : encoder output , \n",
    "        # value : encoder output , \n",
    "        # mask ; pad_tensor of decoder input\n",
    "        mha_tensor = self.mha_layer[i](h_tensor , en_out_tensor , en_out_tensor , pad_tensor)\n",
    "        mha_tensor = self.drop_layer(mha_tensor)\n",
    "        a_tensor = self.norm_layer(mha_tensor + h_tensor)\n",
    "\n",
    "        ff_tensor = self.ff_layer[i](a_tensor)\n",
    "        ff_tensor = self.drop_layer(ff_tensor)\n",
    "        o_tensor = self.norm_layer(a_tensor + ff_tensor)\n",
    "\n",
    "        return o_tensor\n",
    "\n",
    "    def forward(self , in_tensor , en_out_tensor , pad_tensor) :\n",
    "        mask_tensor = self.la_mask(pad_tensor)\n",
    "\n",
    "        tensor_ptr = in_tensor\n",
    "        for i in range(self.layer_size) :\n",
    "            tensor_ptr = self.forward_block(i , tensor_ptr , en_out_tensor , pad_tensor , mask_tensor)\n",
    "        \n",
    "        return tensor_ptr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "56f18ef1-67de-474b-b364-68def7cee4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module) :\n",
    "\n",
    "    def __init__(self, layer_size, sen_size, en_vocabs, de_vocabs,\n",
    "                 d_model , num_heads , hidden_size , drop_rate , norm_rate , cuda_flag) :\n",
    "        super(Transformer , self).__init__()\n",
    "        self.layer_size = layer_size\n",
    "        self.sen_size = sen_size\n",
    "        self.en_vocabs = en_vocabs\n",
    "        self.de_vocabs = de_vocabs\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.en_em = nn.Embedding(num_embeddings=en_vocabs, embedding_dim=d_model, padding_idx=0)\n",
    "        self.de_em = nn.Embedding(num_embeddings=de_vocabs, embedding_dim=d_model, padding_idx=0)\n",
    "        \n",
    "        self.en_pos = PositionalEncoding(sen_size , d_model , cuda_flag)\n",
    "        self.de_pos = PositionalEncoding(sen_size , d_model , cuda_flag)\n",
    "\n",
    "        self.en_pad = PaddingMask(sen_size)\n",
    "        self.de_pad = PaddingMask(sen_size)\n",
    "\n",
    "        self.en = Encoder(layer_size , sen_size , d_model , num_heads , hidden_size , drop_rate , norm_rate , cuda_flag)\n",
    "        self.de = Decoder(layer_size , sen_size , d_model , num_heads , hidden_size , drop_rate , norm_rate , cuda_flag)\n",
    "\n",
    "        self.o_layer = nn.Linear(d_model , de_vocabs)\n",
    "\n",
    "        self.init_param()\n",
    "\n",
    "    def init_param(self) :\n",
    "        nn.init.normal_(self.en_em.weight, mean=0.0, std=0.1)\n",
    "        nn.init.normal_(self.de_em.weight, mean=0.0, std=0.1)\n",
    "\n",
    "        nn.init.xavier_normal_(self.o_layer.weight)\n",
    "        nn.init.zeros_(self.o_layer.bias)\n",
    "\n",
    "    def get_encoder(self) :\n",
    "        return {'embedding' : self.en_em, \n",
    "                'encoding' : self.en_pos, \n",
    "                'padding' : self.en_pad,\n",
    "                'encoder' : self.en}\n",
    "\n",
    "    def get_decoder(self) :\n",
    "        return {'embedding' : self.de_em, \n",
    "                'encoding' : self.de_pos, \n",
    "                'padding' : self.de_pad,\n",
    "                'encoder' : self.de}\n",
    "\n",
    "    def get_output(self) :\n",
    "        return self.o_layer\n",
    "\n",
    "    def forward(self , en_in_tensor , de_in_tensor) :\n",
    "        en_pad_tensor = self.en_pad(en_in_tensor) # padding\n",
    "        en_em_tensor = self.en_em(en_in_tensor) # embedding\n",
    "        en_pos_tensor = self.en_pos(en_em_tensor) # positional encoding\n",
    "\n",
    "        de_pad_tensor = self.de_pad(de_in_tensor) # padding\n",
    "        de_em_tensor = self.de_em(de_in_tensor) # embedding\n",
    "        de_pos_tensor = self.de_pos(de_em_tensor) # positional encoding\n",
    "\n",
    "        en_out = self.en(en_pos_tensor , en_pad_tensor) # encoder output\n",
    "        de_out = self.de(de_pos_tensor , en_out , de_pad_tensor) # deocder output\n",
    "\n",
    "        o_tensor = self.o_layer(de_out) # linear layer \n",
    "        o_tensor = o_tensor.view([-1, self.de_vocabs])\n",
    "    \n",
    "        return o_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41111527-b748-4ea7-8d28-38fc98ea6de1",
   "metadata": {},
   "source": [
    "## Model Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "34e2ebd6-6db0-44b2-8197-88c8a768da97",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_v_size = en_encoder.get_size()\n",
    "kor_v_size = kor_encoder.get_size()\n",
    "\n",
    "layer_size = 6\n",
    "sen_size = 25\n",
    "d_model = 512\n",
    "num_heads = 8\n",
    "h_size = 2048\n",
    "drop_rate = 1e-1\n",
    "norm_rate = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4a32cc66-d3cd-4dda-829d-03ceb495d9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(layer_size, sen_size, kor_v_size, en_v_size, \n",
    "                          d_model, num_heads, h_size, drop_rate, norm_rate, use_cuda)\n",
    "\n",
    "transformer = transformer.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7beeb5a7-fcdf-4cf4-9685-351d1ccb1605",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "605b9618-1a19-4fb6-aca1-eebc7ff3392c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dumb_lr = 1e-4 # no meaning\n",
    "\n",
    "epoch_size = int(100000 / len(train_loader))\n",
    "warmup_steps = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ff579e67-7775-4655-8ded-a26de77216a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def schedule_fn(epoch, d_model, dumb_lr) :\n",
    "    step_num = epoch + 1\n",
    "    val1 = d_model ** (-0.5)\n",
    "    \n",
    "    arg1 = step_num ** (-0.5)\n",
    "    arg2 = (warmup_steps ** (-1.5)) * step_num\n",
    "    \n",
    "    val2 = min(arg1 , arg2) \n",
    "    return (val1 * val2) / dumb_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "57880e66-2a15-473a-b3f0-dac6a4f3c5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(transformer.parameters(), lr=dumb_lr, betas=(0.9,0.98), eps=1e-9)\n",
    "scheduler = optim.lr_scheduler.LambdaLR(optimizer, \n",
    "                                        lr_lambda = lambda epoch: schedule_fn(epoch, d_model, dumb_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd58022f-68c0-48cb-a5aa-0abeee8c04e0",
   "metadata": {},
   "source": [
    "## Acc & Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7674d10b-b778-4e8d-8968-c7e97c397210",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_fn(y_output , y_label) :\n",
    "    \n",
    "    y_arg = torch.argmax(y_output, dim=-1)\n",
    "    y_acc = (y_arg == y_label).float()\n",
    "\n",
    "    y_acc = torch.mean(y_acc)\n",
    "    \n",
    "    return y_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "60f934ae-b533-4c39-b58d-76a4275ecee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fb6adb-fc5d-4eaa-a93b-eaf41c3a0796",
   "metadata": {},
   "source": [
    "## Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "55dc8431-65d7-4f84-bcc7-b0c2a5fede3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('./Log/runs/transformer/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0a6849-f33f-455c-8d41-2177c5137e4d",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "818615d4-75e6-46a2-bf30-a52a70ac4651",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_loss = np.inf\n",
    "stop_count = 0\n",
    "log_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "14b1a8fe-0ccf-4867-b97b-1484de12e7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def progressLearning(value, endvalue, loss , acc , bar_length=50):\n",
    "      \n",
    "    percent = float(value + 1) / endvalue\n",
    "    arrow = '-' * int(round(percent * bar_length)-1) + '>'\n",
    "    spaces = ' ' * (bar_length - len(arrow))\n",
    "\n",
    "    sys.stdout.write(\"\\rPercent: [{0}] {1}/{2} \\t Loss : {3:.3f} , Acc : {4:.3f}\".format(arrow + spaces, value+1 , endvalue , loss , acc))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6dc38a61-8290-4ce8-a49c-66f2d382e14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader) :\n",
    "\n",
    "    with torch.no_grad() :\n",
    "        model.eval()\n",
    "\n",
    "        loss_eval = 0.0\n",
    "        acc_eval = 0.0\n",
    "\n",
    "        for data in test_loader :\n",
    "\n",
    "            en_in = data['encoder_in'].long().to(device)\n",
    "            de_in = data['decoder_in'].long().to(device)\n",
    "            de_label = data['decoder_out'].long().to(device)\n",
    "            \n",
    "            de_label = data['decoder_out'].long().to(device)\n",
    "            de_label = de_label.view([-1,])\n",
    "            \n",
    "            de_output = model(en_in , de_in)\n",
    "\n",
    "            loss = loss_fn(de_output , de_label)\n",
    "            acc = acc_fn(de_output , de_label)\n",
    "\n",
    "            loss_eval += loss\n",
    "            acc_eval += acc\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        loss_eval /= len(test_loader)\n",
    "        acc_eval /= len(test_loader)\n",
    "\n",
    "    return loss_eval , acc_eval  \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca61e80-5052-4c67-8e04-aff681fc8374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 \t Learning Rate : 3.493856e-07\n",
      "Percent: [------------------------------------------------->] 1500/1500 \t Loss : 6.433 , Acc : 0.367\n",
      "Val Loss : 6.358 \t Val Accuracy : 0.364\n",
      "\n",
      "Epoch : 1 \t Learning Rate : 5.240784e-07\n",
      "Percent: [------------------------------------------------->] 1500/1500 \t Loss : 5.887 , Acc : 0.338\n",
      "Val Loss : 5.577 \t Val Accuracy : 0.391\n",
      "\n",
      "Epoch : 2 \t Learning Rate : 6.987712e-07\n",
      "Percent: [------------------------------------------------->] 1500/1500 \t Loss : 5.166 , Acc : 0.378\n",
      "Val Loss : 4.873 \t Val Accuracy : 0.415\n",
      "\n",
      "Epoch : 3 \t Learning Rate : 8.734641e-07\n",
      "Percent: [------------------------------------------------->] 1500/1500 \t Loss : 4.304 , Acc : 0.433\n",
      "Val Loss : 4.272 \t Val Accuracy : 0.427\n",
      "\n",
      "Epoch : 4 \t Learning Rate : 1.048157e-06\n",
      "Percent: [------------------------------------------------->] 1500/1500 \t Loss : 3.835 , Acc : 0.444\n",
      "Val Loss : 3.809 \t Val Accuracy : 0.449\n",
      "\n",
      "Epoch : 5 \t Learning Rate : 1.222850e-06\n",
      "Percent: [------------------------------------------------->] 1500/1500 \t Loss : 3.518 , Acc : 0.477\n",
      "Val Loss : 3.537 \t Val Accuracy : 0.476\n",
      "\n",
      "Epoch : 6 \t Learning Rate : 1.397542e-06\n",
      "Percent: [------------------------------------------------->] 1500/1500 \t Loss : 3.572 , Acc : 0.469\n",
      "Val Loss : 3.395 \t Val Accuracy : 0.489\n",
      "\n",
      "Epoch : 7 \t Learning Rate : 1.572235e-06\n",
      "Percent: [------------------------------------------------->] 1500/1500 \t Loss : 3.436 , Acc : 0.475\n",
      "Val Loss : 3.254 \t Val Accuracy : 0.505\n",
      "\n",
      "Epoch : 8 \t Learning Rate : 1.746928e-06\n",
      "Percent: [------------------------------------------------->] 1500/1500 \t Loss : 3.145 , Acc : 0.527\n",
      "Val Loss : 3.131 \t Val Accuracy : 0.519\n",
      "\n",
      "Epoch : 9 \t Learning Rate : 1.921621e-06\n",
      "Percent: [------------------------------------------------->] 1500/1500 \t Loss : 3.170 , Acc : 0.493\n",
      "Val Loss : 3.022 \t Val Accuracy : 0.530\n",
      "\n",
      "Epoch : 10 \t Learning Rate : 2.096314e-06\n",
      "Percent: [------------------------------------------------->] 1500/1500 \t Loss : 2.893 , Acc : 0.549\n",
      "Val Loss : 2.932 \t Val Accuracy : 0.538\n",
      "\n",
      "Epoch : 11 \t Learning Rate : 2.271007e-06\n",
      "Percent: [------------------------------------------------->] 1500/1500 \t Loss : 2.744 , Acc : 0.559\n",
      "Val Loss : 2.854 \t Val Accuracy : 0.545\n",
      "\n",
      "Epoch : 12 \t Learning Rate : 2.445699e-06\n",
      "Percent: [------------------------------------------------->] 1500/1500 \t Loss : 2.849 , Acc : 0.543\n",
      "Val Loss : 2.789 \t Val Accuracy : 0.551\n",
      "\n",
      "Epoch : 13 \t Learning Rate : 2.620392e-06\n",
      "Percent: [------------------------------------------------->] 1500/1500 \t Loss : 2.426 , Acc : 0.599\n",
      "Val Loss : 2.731 \t Val Accuracy : 0.557\n",
      "\n",
      "Epoch : 14 \t Learning Rate : 2.795085e-06\n",
      "Percent: [------------------------------------------------->] 1500/1500 \t Loss : 2.865 , Acc : 0.533\n",
      "Val Loss : 2.680 \t Val Accuracy : 0.561\n",
      "\n",
      "Epoch : 15 \t Learning Rate : 2.969778e-06\n",
      "Percent: [------------------------------------------------->] 1500/1500 \t Loss : 2.531 , Acc : 0.578\n",
      "Val Loss : 2.636 \t Val Accuracy : 0.566\n",
      "\n",
      "Epoch : 16 \t Learning Rate : 3.144471e-06\n",
      "Percent: [------------------------------------------------->] 1500/1500 \t Loss : 2.668 , Acc : 0.545\n",
      "Val Loss : 2.595 \t Val Accuracy : 0.569\n",
      "\n",
      "Epoch : 17 \t Learning Rate : 3.319163e-06\n",
      "Percent: [------------------------------------------------->] 1500/1500 \t Loss : 2.463 , Acc : 0.591\n",
      "Val Loss : 2.556 \t Val Accuracy : 0.573\n",
      "\n",
      "Epoch : 18 \t Learning Rate : 3.493856e-06\n",
      "Percent: [------------------------------------------------->] 1500/1500 \t Loss : 2.515 , Acc : 0.574\n",
      "Val Loss : 2.524 \t Val Accuracy : 0.576\n",
      "\n",
      "Epoch : 19 \t Learning Rate : 3.668549e-06\n",
      "Percent: [-------------------------------->                 ] 978/1500 \t Loss : 2.491 , Acc : 0.575"
     ]
    }
   ],
   "source": [
    "for epoch in range(int(epoch_size/2)) :\n",
    "\n",
    "    idx = 0\n",
    "    lr_idx = optimizer.param_groups[0]['lr']\n",
    "\n",
    "    print('Epoch : %d \\t Learning Rate : %e' %(epoch , lr_idx))\n",
    "\n",
    "    for data in train_loader :\n",
    "        en_in = data['encoder_in'].long().to(device)\n",
    "        de_in = data['decoder_in'].long().to(device)\n",
    "        \n",
    "        de_label = data['decoder_out'].long().to(device)\n",
    "        de_label = de_label.view([-1,])\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        de_output = transformer(en_in , de_in)\n",
    "\n",
    "        loss = loss_fn(de_output , de_label)\n",
    "        acc = acc_fn(de_output , de_label)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        progressLearning(idx, len(train_loader), loss.item(), acc.item())\n",
    "\n",
    "        if (idx + 1) % 10 == 0 :\n",
    "            writer.add_scalar('train/loss' , loss.item() , log_count)\n",
    "            writer.add_scalar('train/acc' , acc.item() , log_count)\n",
    "            log_count += 1\n",
    "        \n",
    "        idx += 1\n",
    "\n",
    "    val_loss, val_acc = evaluate(transformer, val_loader)\n",
    "        \n",
    "    writer.add_scalar('test/loss' , val_loss.item() , epoch)\n",
    "    writer.add_scalar('test/acc' , val_acc.item() , epoch)\n",
    "    \n",
    "    if val_loss < min_loss :\n",
    "        min_loss = val_loss\n",
    "        torch.save({'epoch' : (epoch) ,  \n",
    "                    'model_state_dict' : transformer.state_dict() , \n",
    "                    'loss' : val_loss.item() , \n",
    "                    'acc' : val_acc.item()} , \n",
    "                    f'./Model/checkpoint_transformer.pt')        \n",
    "        stop_count = 0 \n",
    "    \n",
    "    else :\n",
    "        stop_count += 1\n",
    "        if stop_count >= 5 :      \n",
    "            print('\\nTraining Early Stopped')\n",
    "            break\n",
    "\n",
    "    scheduler.step()\n",
    "    print('\\nVal Loss : %.3f \\t Val Accuracy : %.3f\\n' %(val_loss, val_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb62bba-f081-493a-9991-5924a3625758",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3c3663-8f23-41c9-971d-3f4abc5c3ae5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
