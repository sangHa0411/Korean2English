{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "fL0t26SV0Fmn"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "dsc9hM6L0H9b"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader , Subset, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "_LSl4j_VBk3h"
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "y2-9JefyqPyE"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from preprocessor.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "import preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from konlpy.tag import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mecab = Mecab()\n",
    "ko_tokenize = mecab.morphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = '../../Data/'\n",
    "data = pd.read_excel(dir_path + '한국어_대화체_번역.xlsx' , engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_data = data['번역문']\n",
    "kor_data = data['원문']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_vs = preprocessor.VocabSet(word_tokenize)\n",
    "en_tokens = en_vs.tokens(en_data)\n",
    "en_encoder = preprocessor.Encoder(en_data, word_tokenize, en_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "kor_vs = preprocessor.VocabSet(mecab.morphs)\n",
    "kor_tokens = kor_vs.tokens(kor_data)\n",
    "kor_encoder = preprocessor.Encoder(kor_data, mecab.morphs, kor_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_encoded = en_encoder.encode()\n",
    "kor_encoded = kor_encoder.encode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_array = pad_sequences(en_encoded, maxlen=max_len+1, padding='post')\n",
    "kor_array = pad_sequences(kor_encoded, maxlen=max_len, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoderDataset(Dataset) :\n",
    "\n",
    "    def __init__(self , en_encoded , de_encoded , val_ratio=0.9) :\n",
    "\n",
    "        super(EncoderDecoderDataset , self).__init__()\n",
    "        \n",
    "        self.en_in = en_encoded\n",
    "        self.de_in = de_encoded[:,:-1]\n",
    "        self.de_out = de_encoded[:,1:]\n",
    "        \n",
    "        self.val_ratio = val_ratio\n",
    "\n",
    "    def __len__(self) :\n",
    "\n",
    "        return len(self.en_in)\n",
    "\n",
    "    def __getitem__(self , idx) :\n",
    "\n",
    "        en_in_idx = self.en_in[idx]\n",
    "        de_in_idx = self.de_in[idx]\n",
    "        de_out_idx = self.de_out[idx]\n",
    "        \n",
    "        return {'encoder_in' : en_in_idx, 'decoder_in' : de_in_idx, 'decoder_out' : de_out_idx}\n",
    "    \n",
    "    def split_dataset(self) :\n",
    "\n",
    "        n_val = int(len(self) * self.val_ratio)\n",
    "        n_train = len(self) - n_val\n",
    "        train_set, val_set = random_split(self, [n_train, n_val])\n",
    "        \n",
    "        return train_set, val_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = EncoderDecoderDataset(kor_array, en_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(dataset ,\n",
    "                         batch_size = 256,\n",
    "                         num_workers = 4,\n",
    "                         shuffle = True,\n",
    "                         drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PaddingMask(nn.Module) :\n",
    "\n",
    "    def __init__(self, sen_size) :\n",
    "        super(PaddingMask , self).__init__() \n",
    "        self.sen_size = sen_size\n",
    "    \n",
    "    def forward(self, in_tensor) :\n",
    "        batch_size = in_tensor.shape[0]\n",
    "        # mask tensor which element is 0.0\n",
    "        flag_tensor = torch.where(in_tensor == 0.0 , 1.0 , 0.0)\n",
    "        # shape : (batch_size, 1, 1, sen_size)\n",
    "        flag_tensor = torch.reshape(flag_tensor , (batch_size, 1, 1, self.sen_size)) \n",
    "        \n",
    "        return flag_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LookAheadMask(nn.Module) :\n",
    "\n",
    "    def __init__(self, sen_size, cuda_flag) :\n",
    "        super(LookAheadMask, self).__init__() \n",
    "        self.sen_size = sen_size\n",
    "        self.mask_tensor = self.get_mask(sen_size).cuda() if cuda_flag else self.get_mask(sen_size)\n",
    "\n",
    "    def get_mask(self, sen_size) :\n",
    "        # masking tensor\n",
    "        mask_array = 1 - np.tril(np.ones((sen_size,sen_size)) , 0)\n",
    "        mask_tensor = torch.tensor(mask_array , dtype = torch.float32 , requires_grad=False)\n",
    "        mask_tensor = mask_tensor.unsqueeze(0) # shape : (1, sen_size, sen_size)\n",
    "\n",
    "        return mask_tensor\n",
    "    \n",
    "    def forward(self, in_tensor) :\n",
    "        mask_tensor = torch.maximum(in_tensor, self.mask_tensor)\n",
    "\n",
    "        return mask_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module) :\n",
    "\n",
    "    def __init__(self, pos_len, d_model, cuda_flag) :\n",
    "\n",
    "        super(PositionalEncoding , self).__init__()\n",
    "        self.pos_len = pos_len\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # w : weight\n",
    "        # pe : Encoding tensor\n",
    "        if cuda_flag == True :\n",
    "            self.w = torch.sqrt(torch.tensor(d_model, dtype=torch.float32, requires_grad=False)).cuda()\n",
    "            self.pe = self.get_embedding(pos_len, d_model).cuda()\n",
    "\n",
    "        else :\n",
    "            self.w = torch.sqrt(torch.tensor(d_model, dtype=torch.float32, requires_grad=False))\n",
    "            self.pe = self.get_embedding(pos_len, d_model)\n",
    "\n",
    "    # Embedding tensor : (batch_size, sen_size, embedding_dimension)\n",
    "    # Making Encoding tensor (1, sen_size, embedding_dimension)\n",
    "    def get_embedding(self, pos_len, d_model) :\n",
    "        pos_vec = torch.arange(pos_len).float()\n",
    "        pos_vec = pos_vec.unsqueeze(1)\n",
    "\n",
    "        i_vec = torch.arange(d_model).float() / 2\n",
    "        i_vec = torch.floor(i_vec) * 2\n",
    "        i_vec = i_vec.unsqueeze(0) / d_model\n",
    "        i_vec = 1 / torch.pow(1e+4 , i_vec)\n",
    "\n",
    "        em = torch.matmul(pos_vec, i_vec)\n",
    "        pe = torch.zeros(pos_len, d_model, requires_grad=False)\n",
    "\n",
    "        sin_em = torch.sin(em)\n",
    "        cos_em = torch.cos(em)\n",
    "\n",
    "        pe[:,::2] = sin_em[:,::2]\n",
    "        pe[:,1::2] = cos_em[:,1::2]\n",
    "\n",
    "        pe = pe.unsqueeze(0)\n",
    "\n",
    "        return pe\n",
    "\n",
    "    def forward(self, in_tensor) :\n",
    "        en_tensor = in_tensor * self.w + self.pe\n",
    "        \n",
    "        return en_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module) :\n",
    "\n",
    "    def __init__(self, sen_size,  d_model, num_heads) :\n",
    "\n",
    "        super(MultiHeadAttention , self).__init__()\n",
    "        self.sen_size = sen_size # sen_size\n",
    "        self.d_model = d_model # embedidng_dim\n",
    "        self.num_heads = num_heads # head_size\n",
    "        self.depth = int(d_model / num_heads) # embedding_dim / num_heads\n",
    "\n",
    "        self.q_layer = nn.Linear(d_model , d_model)\n",
    "        self.k_layer = nn.Linear(d_model , d_model)\n",
    "        self.v_layer = nn.Linear(d_model , d_model)\n",
    "        self.o_layer = nn.Linear(d_model , d_model)\n",
    "\n",
    "        self.scale = torch.sqrt(torch.tensor(self.depth , dtype=torch.float32 , requires_grad=False))\n",
    "        \n",
    "        self.init_param()\n",
    "\n",
    "    def split(self, tensor) :\n",
    "        tensor = torch.reshape(tensor , (-1 , self.sen_size , self.num_heads , self.depth)) # (batch_size, sen_size, num_heads, depth)\n",
    "        tensor = torch.transpose(tensor , 2 , 1) # batch_size, num_heads, sen_size, depth)\n",
    "\n",
    "        return tensor\n",
    "\n",
    "    def merge(self, tensor) :\n",
    "        tensor = torch.transpose(tensor , 2 , 1) # (batch_size, sen_size, num_heads, depth)\n",
    "        tensor = torch.reshape(tensor , (-1 , self.sen_size , self.d_model)) # (batch_size , sen_size , embedding_dim)\n",
    "\n",
    "        return tensor\n",
    "\n",
    "    def scaled_dot_production(self, q_tensor, k_tensor, v_tensor, m_tensor) :\n",
    "        q_tensor = self.split(q_tensor)\n",
    "        k_tensor = self.split(k_tensor)\n",
    "        v_tensor = self.split(v_tensor)\n",
    "        \n",
    "        k_tensor_T = torch.transpose(k_tensor , 3 , 2) # (batch_size, num_heads, depth, sen_size)\n",
    "\n",
    "        qk_tensor = torch.matmul(q_tensor , k_tensor_T) # (batch_size, num_heads, sen_size, sen_size)\n",
    "        qk_tensor /= self.scale\n",
    "\n",
    "        # pad mask tensor shape : (batch_size, 1, 1, sen_size)\n",
    "        # lookahead mask tensor shape : (batch_size, 1, sen_size, sen_size)\n",
    "        if m_tensor != None :\n",
    "            qk_tensor -= (m_tensor * 1e+6)\n",
    "\n",
    "        qk_tensor = F.softmax(qk_tensor , dim = -1)\n",
    "        att = torch.matmul(qk_tensor , v_tensor) # (batch_size, num_heads, sen_size, depth)\n",
    "\n",
    "        return att\n",
    "\n",
    "    # Xavier Initialization\n",
    "    def init_param(self) :\n",
    "        for m in self.modules() :\n",
    "            if isinstance(m,nn.Linear) :\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, q_in, k_in, v_in, m_in) :\n",
    "        q_tensor = self.q_layer(q_in)\n",
    "        k_tensor = self.k_layer(k_in)\n",
    "        v_tensor = self.v_layer(v_in)\n",
    "\n",
    "        att_tensor = self.scaled_dot_production(q_tensor , k_tensor , v_tensor , m_in)\n",
    "        att_tensor = self.merge(att_tensor)\n",
    "\n",
    "        o_tensor = self.o_layer(att_tensor)\n",
    "\n",
    "        return o_tensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module) :\n",
    "\n",
    "    def __init__(self, hidden_size, d_model) :\n",
    "\n",
    "        super(FeedForward , self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        # relu activation and input, output dim are same\n",
    "        self.ff = nn.Sequential(nn.Linear(d_model , hidden_size), \n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(hidden_size , d_model))\n",
    "\n",
    "        self.init_param()\n",
    "                \n",
    "    # He Initialization\n",
    "    def init_param(self) :\n",
    "        gain = 2 ** (1/2)\n",
    "        \n",
    "        for m in self.modules() :\n",
    "            if isinstance(m , nn.Linear) :\n",
    "                nn.init.kaiming_normal_(m.weight , gain)\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self , in_tensor) :\n",
    "        o_tensor = self.ff(in_tensor)\n",
    "\n",
    "        return o_tensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module) :\n",
    "\n",
    "    def __init__(self, layer_size, sen_size, d_model, num_heads, hidden_size, drop_rate, norm_rate, cuda_flag) :\n",
    "\n",
    "        super(Encoder , self).__init__()\n",
    "        self.layer_size = layer_size\n",
    "        self.sen_size = sen_size\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.mha_layer = nn.ModuleList()\n",
    "        self.ff_layer = nn.ModuleList()\n",
    "        self.drop_layer = nn.Dropout(drop_rate)\n",
    "        self.norm_layer = nn.LayerNorm(d_model , eps=norm_rate)\n",
    "\n",
    "        for i in range(layer_size) :\n",
    "            # multihead attention layer\n",
    "            mha_idx = MultiHeadAttention(sen_size , d_model , num_heads)\n",
    "            self.mha_layer.append(mha_idx)\n",
    "            \n",
    "            # feedforward layer\n",
    "            ff_idx = FeedForward(hidden_size , d_model)\n",
    "            self.ff_layer.append(ff_idx)\n",
    "\n",
    "    def forward_block(self, i, in_tensor, pad_tensor) :\n",
    "        # query : encoder input\n",
    "        # key : encoder input \n",
    "        # value : encoder input\n",
    "        # mask ; pad_tensor of encoder input\n",
    "        mha_tensor = self.mha_layer[i](in_tensor , in_tensor , in_tensor , pad_tensor)\n",
    "        mha_tensor = self.drop_layer(mha_tensor)\n",
    "        h_tensor = self.norm_layer(in_tensor + mha_tensor)\n",
    "\n",
    "        ff_tensor = self.ff_layer[i](h_tensor)\n",
    "        ff_tensor = self.drop_layer(ff_tensor)\n",
    "        o_tensor = self.norm_layer(h_tensor + ff_tensor)\n",
    "\n",
    "        return o_tensor\n",
    "\n",
    "    def forward(self , in_tensor , pad_tensor) :\n",
    "        tensor_ptr = in_tensor\n",
    "\n",
    "        for i in range(self.layer_size) :\n",
    "            tensor_ptr = self.forward_block(i , tensor_ptr , pad_tensor)\n",
    "        \n",
    "        return tensor_ptr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module) :\n",
    "\n",
    "    def __init__(self, layer_size, sen_size, d_model, num_heads, hidden_size, drop_rate, norm_rate, cuda_flag) :\n",
    "\n",
    "        super(Decoder , self).__init__()\n",
    "        self.layer_size = layer_size\n",
    "        self.sen_size = sen_size\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.m_mha_layer = nn.ModuleList()\n",
    "        self.mha_layer = nn.ModuleList()\n",
    "        self.ff_layer = nn.ModuleList()\n",
    "\n",
    "        self.drop_layer = nn.Dropout(drop_rate)\n",
    "        self.norm_layer = nn.LayerNorm(d_model , eps=norm_rate)\n",
    "\n",
    "        self.la_mask = LookAheadMask(sen_size , cuda_flag)\n",
    "\n",
    "        for i in range(layer_size) :\n",
    "            m_mha_idx = MultiHeadAttention(sen_size , d_model , num_heads)\n",
    "            # masked multihead attention layer\n",
    "            self.m_mha_layer.append(m_mha_idx)\n",
    "\n",
    "            mha_idx = MultiHeadAttention(sen_size , d_model , num_heads)\n",
    "            # multihead attention layer\n",
    "            self.mha_layer.append(mha_idx)\n",
    "\n",
    "            ff_idx = FeedForward(hidden_size , d_model)\n",
    "            # feedforward layer\n",
    "            self.ff_layer.append(ff_idx)\n",
    "\n",
    "    def forward_block(self, i, in_tensor, en_out_tensor, pad_tensor, mask_tensor) :\n",
    "        # query : in_tensor\n",
    "        # key : in_tensor \n",
    "        # value : in_tensor \n",
    "        # mask ; look ahead mask\n",
    "        m_mha_tensor = self.m_mha_layer[i](in_tensor , in_tensor , in_tensor , mask_tensor)\n",
    "        m_mha_tensor = self.drop_layer(m_mha_tensor)\n",
    "        h_tensor = self.norm_layer(in_tensor + m_mha_tensor)\n",
    "\n",
    "        # query : output of masked multihead attention\n",
    "        # key : encoder output , \n",
    "        # value : encoder output , \n",
    "        # mask ; pad_tensor of decoder input\n",
    "        mha_tensor = self.mha_layer[i](h_tensor , en_out_tensor , en_out_tensor , pad_tensor)\n",
    "        mha_tensor = self.drop_layer(mha_tensor)\n",
    "        a_tensor = self.norm_layer(mha_tensor + h_tensor)\n",
    "\n",
    "        ff_tensor = self.ff_layer[i](a_tensor)\n",
    "        ff_tensor = self.drop_layer(ff_tensor)\n",
    "        o_tensor = self.norm_layer(a_tensor + ff_tensor)\n",
    "\n",
    "        return o_tensor\n",
    "\n",
    "    def forward(self , in_tensor , en_out_tensor , pad_tensor) :\n",
    "        mask_tensor = self.la_mask(pad_tensor)\n",
    "\n",
    "        tensor_ptr = in_tensor\n",
    "        for i in range(self.layer_size) :\n",
    "            tensor_ptr = self.forward_block(i , tensor_ptr , en_out_tensor , pad_tensor , mask_tensor)\n",
    "        \n",
    "        return tensor_ptr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module) :\n",
    "\n",
    "    def __init__(self, layer_size, sen_size, en_vocabs, de_vocabs,\n",
    "                 d_model , num_heads , hidden_size , drop_rate , norm_rate , cuda_flag) :\n",
    "\n",
    "        super(Transformer , self).__init__()\n",
    "\n",
    "        self.en_em = nn.Embedding(num_embeddings=en_vocabs, embedding_dim=d_model, padding_idx=0)\n",
    "        self.de_em = nn.Embedding(num_embeddings=de_vocabs, embedding_dim=d_model, padding_idx=0)\n",
    "        \n",
    "        self.en_pos = PositionalEncoding(sen_size , d_model , cuda_flag)\n",
    "        self.de_pos = PositionalEncoding(sen_size , d_model , cuda_flag)\n",
    "\n",
    "        self.en_pad = PaddingMask(sen_size)\n",
    "        self.de_pad = PaddingMask(sen_size)\n",
    "\n",
    "        self.en = Encoder(layer_size , sen_size , d_model , num_heads , hidden_size , drop_rate , norm_rate , cuda_flag)\n",
    "        self.de = Decoder(layer_size , sen_size , d_model , num_heads , hidden_size , drop_rate , norm_rate , cuda_flag)\n",
    "\n",
    "        self.o_layer = nn.Linear(d_model , de_vocabs)\n",
    "\n",
    "        self.init_param()\n",
    "\n",
    "    def init_param(self) :\n",
    "\n",
    "        nn.init.xavier_normal_(self.o_layer.weight)\n",
    "        nn.init.zeros_(self.o_layer.bias)\n",
    "\n",
    "    def get_encoder(self) :\n",
    "\n",
    "        return {'embedding' : self.en_em, \n",
    "                'encoding' : self.en_pos, \n",
    "                'padding' : self.en_pad,\n",
    "                'encoder' : self.en}\n",
    "\n",
    "    def get_decoder(self) :\n",
    "\n",
    "        return {'embedding' : self.de_em, \n",
    "                'encoding' : self.de_pos, \n",
    "                'padding' : self.de_pad,\n",
    "                'encoder' : self.de}\n",
    "\n",
    "    def get_output(self) :\n",
    "\n",
    "        return self.o_layer\n",
    "\n",
    "    def forward(self , en_in_tensor , de_in_tensor) :\n",
    "        en_pad_tensor = self.en_pad(en_in_tensor) # padding\n",
    "        en_em_tensor = self.en_em(en_in_tensor) # embedding\n",
    "        en_pos_tensor = self.en_pos(en_em_tensor) # positional encoding\n",
    "\n",
    "        de_pad_tensor = self.de_pad(de_in_tensor) # padding\n",
    "        de_em_tensor = self.de_em(de_in_tensor) # embedding\n",
    "        de_pos_tensor = self.de_pos(de_em_tensor) # positional encoding\n",
    "\n",
    "        en_out = self.en(en_pos_tensor , en_pad_tensor) # encoder output\n",
    "        de_out = self.de(de_pos_tensor , en_out , de_pad_tensor) # deocder output\n",
    "\n",
    "        pred_tensor = self.o_layer(de_out) # linear layer \n",
    "        prob_tensor = F.softmax(pred_tensor , dim = -1) # calcuate probablity\n",
    "\n",
    "        return prob_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_v_size = en_encoder.get_size()\n",
    "kor_v_size = kor_encoder.get_size()\n",
    "\n",
    "layer_size = 6\n",
    "sen_size = 30\n",
    "d_model = 512\n",
    "num_heads = 8\n",
    "h_size = 2048\n",
    "drop_rate = 1e-1\n",
    "norm_rate = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(layer_size, sen_size, kor_v_size, en_v_size,\n",
    "                          d_model, num_heads, h_size, drop_rate, norm_rate, use_cuda)\n",
    "\n",
    "transformer = transformer.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTest(unittest.TestCase): \n",
    "    \n",
    "    def setUp(self) :\n",
    "        self.dataset = dataset\n",
    "        self.loader = data_loader\n",
    "        self.model = transformer\n",
    "        self.device = device\n",
    "        \n",
    "        self.sen_size = sen_size\n",
    "        self.en_v_size = en_v_size\n",
    "        self.kor_v_size = kor_v_size\n",
    "        \n",
    "        self.opt = optim.SGD(self.model.parameters() , 1e-3)\n",
    "        self.ce_loss = nn.CrossEntropyLoss().to(self.device)\n",
    "\n",
    "    def loss_fn(self, y_output , y_label) :\n",
    "        y_label = y_label.unsqueeze(2)\n",
    "        y_prob = torch.gather(y_output, -1, y_label)\n",
    "    \n",
    "        y_loss = -torch.log(y_prob+1e-30)\n",
    "\n",
    "        y_loss = torch.mean(y_loss , dim=-1)\n",
    "        y_loss = torch.mean(y_loss)\n",
    "\n",
    "        return y_loss\n",
    "        \n",
    "    # input type , dtype test\n",
    "    def test_type(self) :\n",
    "        sample_data = self.dataset[0]\n",
    "        sample_en_in = sample_data['encoder_in']\n",
    "        sample_de_in = sample_data['decoder_in']\n",
    "        \n",
    "        element_en_in = str(sample_en_in[0].dtype)\n",
    "        element_de_in = str(sample_de_in[0].dtype)\n",
    "   \n",
    "        self.assertIsInstance(sample_en_in , np.ndarray)\n",
    "        self.assertIsInstance(sample_de_in , np.ndarray)\n",
    "        \n",
    "        self.assertEqual(element_en_in , 'int32')\n",
    "        self.assertEqual(element_de_in , 'int32')\n",
    "        \n",
    "    # input dimension test\n",
    "    def test_input_dim(self) :\n",
    "        sample_data = self.dataset[0]\n",
    "        sample_en_in = sample_data['encoder_in']\n",
    "        sample_de_in = sample_data['decoder_in']\n",
    "        \n",
    "        tensor_en_dim = sample_en_in.shape\n",
    "        tensor_de_dim = sample_de_in.shape\n",
    "            \n",
    "        self.assertEqual(tensor_en_dim[0] , sen_size)\n",
    "        self.assertEqual(tensor_de_dim[0] , sen_size)\n",
    "    \n",
    "    # input array range test\n",
    "    def test_input_range(self) :\n",
    "        for data in self.loader :\n",
    "            break\n",
    "        \n",
    "        en_idx = torch.max(data['encoder_in'])\n",
    "        de_idx = torch.max(data['decoder_in'])\n",
    "        \n",
    "        self.assertTrue(en_idx > torch.tensor(0, dtype=torch.int32))\n",
    "        self.assertTrue(en_idx < torch.tensor(self.kor_v_size, dtype=torch.int32))\n",
    "        \n",
    "        self.assertTrue(de_idx > torch.tensor(0, dtype=torch.int32))\n",
    "        self.assertTrue(de_idx < torch.tensor(self.en_v_size, dtype=torch.int32))\n",
    "        \n",
    "    # output dimension test\n",
    "    def test_output_dim(self) :\n",
    "        \n",
    "        for data in self.loader :\n",
    "            break\n",
    "            \n",
    "        en_idx = data['encoder_in'].long().to(device)\n",
    "        de_idx = data['decoder_in'].long().to(device)\n",
    "    \n",
    "        de_out = self.model(en_idx , de_idx)\n",
    "\n",
    "        output_dim = de_out.shape\n",
    "        \n",
    "        self.assertEqual(len(output_dim), 3)\n",
    "        self.assertEqual(output_dim[1], self.sen_size)\n",
    "        self.assertEqual(output_dim[2], self.en_v_size)\n",
    "        \n",
    "    # training test\n",
    "    def test_train(self) :\n",
    "        \n",
    "        # parameters before training\n",
    "        prev_param = [copy.deepcopy(m) for m in self.model.parameters()]\n",
    " \n",
    "        self.opt.zero_grad()\n",
    "            \n",
    "        for data in self.loader :\n",
    "            break\n",
    "            \n",
    "        en_idx = data['encoder_in'].long().to(device)\n",
    "        de_idx = data['decoder_in'].long().to(device)\n",
    "        de_label = data['decoder_out'].long().to(device)\n",
    "    \n",
    "        de_out = self.model(en_idx, de_idx)\n",
    "        \n",
    "        loss = self.loss_fn(de_out, de_label)\n",
    "        \n",
    "        loss.backward()\n",
    "        self.opt.step()\n",
    "        \n",
    "        idx = 0\n",
    "        \n",
    "        # check if parameters are updated\n",
    "        for m in self.model.parameters() :\n",
    "            \n",
    "            self.assertFalse(torch.equal(prev_param[idx] , m))\n",
    "            idx += 1\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_input_dim (__main__.ModelTest) ... ok\n",
      "test_input_range (__main__.ModelTest) ... ok\n",
      "test_output_dim (__main__.ModelTest) ... ok\n",
      "test_train (__main__.ModelTest) ... ok\n",
      "test_type (__main__.ModelTest) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 1.022s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x7f782269ea90>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Vision Transformer_Project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
