{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ffd506-afcb-48f7-924f-7bc4979ced19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import collections\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4a07d5-4aea-4775-ae3f-d93c6f98ba4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372157d3-baff-4b18-9dbb-41c1e3671243",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Token(Enum):\n",
    "    PAD_TOK = '<PAD>'\n",
    "    PAD_IDX = 0\n",
    "    UNK_TOK = '<UNK>'\n",
    "    UNK_IDX = 1\n",
    "    SOS_TOK = '<SOS>'\n",
    "    SOS_IDX = 2\n",
    "    EOS_TOK = '<EOS>'\n",
    "    EOS_IDX = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c701136-fbd6-4c0f-be2e-6bc053df6b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessor :\n",
    "\n",
    "    def __init__(self, data, tokenize, th=3) :\n",
    "        self.token_data = [tokenize(sen.lower()) for sen in data]\n",
    "        self.tokenize = tokenize\n",
    "        self.th = th\n",
    "        \n",
    "        self.word2idx, self.idx2word = self.build_set()\n",
    "        \n",
    "    def build_set(self) :\n",
    "        vocab_set = collections.Counter()\n",
    "        for sen in self.token_data :\n",
    "            vocab_set.update(sen)\n",
    "        \n",
    "        vocab_set = dict(vocab_set)\n",
    "        valid_tok = []\n",
    "        for tok, count in vocab_set.items() : \n",
    "            if count >= self.th and (re.search('[0-9]' , tok) == None) :\n",
    "                valid_tok.append(tok)\n",
    "                \n",
    "        random.shuffle(valid_tok)\n",
    "        tok_list = [Token.PAD_TOK.value,\n",
    "                    Token.UNK_TOK.value, \n",
    "                    Token.SOS_TOK.value, \n",
    "                    Token.EOS_TOK.value] + valid_tok\n",
    "        \n",
    "        word2idx = dict(zip(tok_list, range(len(tok_list))))\n",
    "        idx2word = {word: idx for idx, word in word2idx.items()}\n",
    "        \n",
    "        return word2idx, idx2word\n",
    "        \n",
    "    def __len__(self) :\n",
    "        return len(self.token_data)\n",
    "    \n",
    "    def get_size(self) :\n",
    "        return len(self.word2idx)\n",
    "    \n",
    "    def encode_sen(self, sen) :\n",
    "        idx_list = []\n",
    "        for tok in sen :\n",
    "            if tok not in self.word2idx :\n",
    "                tok = Token.UNK_TOK.value\n",
    "            idx_list.append(self.word2idx[tok])\n",
    "            \n",
    "        idx_list = [Token.SOS_IDX.value] + idx_list + [Token.EOS_IDX.value]\n",
    "        return idx_list\n",
    "    \n",
    "    def encode(self) :\n",
    "        idx_data = [self.encode_sen(sen) for sen in self.token_data]\n",
    "        return idx_data\n",
    "\n",
    "    def decode(self, idx_list) :\n",
    "        return [self.idx2word[idx] for idx in idx_list]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627d8c21-ab9a-41a7-ab99-3d8ba3b7d2b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00b8dd3-911e-4d7a-bf26-41c9e9c89a6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
